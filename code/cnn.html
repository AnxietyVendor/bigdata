<!DOCTYPE html>
<!-- saved from url=(0102)https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9 -->
<html xmlns:cc="http://creativecommons.org/ns#"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=contain"><title>Gentle Dive into Math Behind Convolutional Neural Networks</title><link rel="canonical" href="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"><meta name="title" content="Gentle Dive into Math Behind Convolutional Neural Networks"><meta name="referrer" content="always"><meta name="description" content="Autonomous driving, healthcare or retail are just some of the areas where Computer Vision has allowed us to achieve things that, until recently, were considered impossible. Today the dream of a self…"><meta name="theme-color" content="#000000"><meta property="og:title" content="Gentle Dive into Math Behind Convolutional Neural Networks"><meta property="twitter:title" content="Gentle Dive into Math Behind Convolutional Neural Networks"><meta property="og:url" content="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1200/1*k6hOViVXOteTOwaI_nCvqg.gif"><meta property="fb:app_id" content="542599432471018"><meta property="og:description" content="Mysteries of Neural Networks Part V"><meta name="twitter:description" content="Mysteries of Neural Networks Part V"><meta name="twitter:image:src" content="https://cdn-images-1.medium.com/max/1200/1*k6hOViVXOteTOwaI_nCvqg.gif"><link rel="publisher" href="https://plus.google.com/103654360130207659246"><link rel="author" href="https://towardsdatascience.com/@piotr.skalski92"><meta name="author" content="Piotr Skalski"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta property="article:publisher" content="https://www.facebook.com/towardsdatascience"><meta property="article:author" content="Piotr Skalski"><meta name="robots" content="index, follow"><meta property="article:published_time" content="2019-04-12T21:27:18.283Z"><meta name="twitter:creator" content="@PiotrSkalski92"><meta name="twitter:site" content="@TDataScience"><meta property="og:site_name" content="Towards Data Science"><meta name="twitter:label1" value="Reading time"><meta name="twitter:data1" value="12 min read"><meta name="twitter:app:name:iphone" content="Medium"><meta name="twitter:app:id:iphone" content="828256236"><meta name="twitter:app:url:iphone" content="medium://p/79a07dd44cf9"><meta property="al:ios:app_name" content="Medium"><meta property="al:ios:app_store_id" content="828256236"><meta property="al:android:package" content="com.medium.reader"><meta property="al:android:app_name" content="Medium"><meta property="al:ios:url" content="medium://p/79a07dd44cf9"><meta property="al:android:url" content="medium://p/79a07dd44cf9"><meta property="al:web:url" content="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"><link rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/79a07dd44cf9"><script async="" src="./cnn_files/branch-latest.min.js"></script><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","image":{"@type":"ImageObject","width":618,"height":434,"url":"https://cdn-images-1.medium.com/max/1236/1*k6hOViVXOteTOwaI_nCvqg.gif"},"url":"https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9","dateCreated":"2019-04-12T21:27:18.283Z","datePublished":"2019-04-12T21:27:18.283Z","dateModified":"2019-04-14T18:02:05.196Z","headline":"Gentle Dive into Math Behind Convolutional Neural Networks","name":"Gentle Dive into Math Behind Convolutional Neural Networks","articleId":"79a07dd44cf9","thumbnailUrl":"https://cdn-images-1.medium.com/max/1236/1*k6hOViVXOteTOwaI_nCvqg.gif","keywords":["Tag:Machine Learning","Tag:Deep Learning","Tag:Neural Networks","Tag:Towards Data Science","Tag:Data Science","Topic:Machine Learning","Topic:Data Science","Publication:towards-data-science","LockedPostSource:0","Elevated:false","LayerCake:3"],"author":{"@type":"Person","name":"Piotr Skalski","url":"https://towardsdatascience.com/@piotr.skalski92"},"creator":["Piotr Skalski"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"https://towardsdatascience.com","logo":{"@type":"ImageObject","width":161,"height":60,"url":"https://cdn-images-1.medium.com/max/322/1*5EUO1kUYBthpOCPzRj_l2g.png"}},"mainEntityOfPage":"https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"}</script><meta name="parsely-link" content="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"><link rel="stylesheet" type="text/css" class="js-glyph-" id="glyph-8" href="./cnn_files/m2.css"><link rel="stylesheet" href="./cnn_files/main-branding-base.sMRbh_65n82B91860QdvTg.css"><script>!function(n,e){var t,o,i,c=[],f={passive:!0,capture:!0},r=new Date,a="pointerup",u="pointercancel";function p(n,c){t||(t=c,o=n,i=new Date,w(e),s())}function s(){o>=0&&o<i-r&&(c.forEach(function(n){n(o,t)}),c=[])}function l(t){if(t.cancelable){var o=(t.timeStamp>1e12?new Date:performance.now())-t.timeStamp;"pointerdown"==t.type?function(t,o){function i(){p(t,o),r()}function c(){r()}function r(){e(a,i,f),e(u,c,f)}n(a,i,f),n(u,c,f)}(o,t):p(o,t)}}function w(n){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(e){n(e,l,f)})}w(n),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){c.push(n),s()}}(addEventListener,removeEventListener);</script><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener("error", _onerror, true); else if (document.attachEvent) document.attachEvent("onerror", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("script"); s.type = "text/javascript"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("link"); s.rel = "stylesheet"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = "/_/stat?event=pixel.load&origin=" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga("create", "UA-24232453-2", "auto", {"allowLinker": true, "legacyCookieDomain": window.location.hostname}); ga("send", "pageview");ga("create", "UA-19707169-24", "auto", 'tracker0'); ga("tracker0.send", "pageview");</script><script async="" src="./cnn_files/analytics.js"></script><!--[if lt IE 9]><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js"></script><![endif]--><link rel="icon" href="https://cdn-images-1.medium.com/fit/c/256/256/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg" class="js-favicon"><link rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/304/304/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/240/240/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/152/152/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="60x60" href="./cnn_files/1_F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"></head><body itemscope="" class="postShowScreen browser-chrome os-mac is-withMagicUnderlines v-glyph v-glyph--m2 is-js" data-action-scope="_actionscope_0"><script>document.body.className = document.body.className.replace(/(^|\s)is-noJs(\s|$)/, "$1is-js$2")</script><div class="site-main surface-container" id="container"><div class="butterBar butterBar--error" data-action-scope="_actionscope_1"></div><div class="surface" id="_obv.shell._surface_1555828783385" style="display: block; visibility: visible;"><div class="screenContent surface-content is-supplementalPostContentLoaded" data-used="true" data-action-scope="_actionscope_2"><canvas class="canvas-renderer" width="1268" height="648"></canvas><div class="container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer"><div class="notesMarkers" data-action-scope="_actionscope_4"></div></div><div class="metabar u-clearfix u-boxShadow4px12pxBlackLighter u-textColorTransparentWhiteDarker u-fixed u-backgroundTransparentWhiteDarkest u-xs-sizeFullViewportWidth js-metabar"><div class="branch-journeys-top"></div><div class="js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1032 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingHorizontal20"><div class="metabar-block u-flex1 u-flexCenter"><div class="u-xs-hide js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-xs-show js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div></div><div class="metabar-block u-flex0 u-flexCenter"><div class="u-flexCenter u-height65 u-xs-height56"><div class="buttonSet buttonSet--wide u-lineHeightInherit"><a class="button button--primary button--chromeless u-accentColor--buttonNormal is-inSiteNavBar u-xs-hide js-signInButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9&amp;source=--------------------------nav_reg&amp;operation=login" data-action="sign-in-prompt" data-redirect="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9" data-action-source="--------------------------nav_reg">Sign in</a><a class="button button--primary button--withChrome u-accentColor--buttonNormal is-inSiteNavBar js-signUpButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9&amp;source=--------------------------nav_reg&amp;operation=register" data-action="sign-up-prompt" data-redirect="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9" data-action-source="--------------------------nav_reg">Get started</a></div></div></div></div><div class="u-tintBgColor u-tintSpectrum "><div class="metabar-inner u-marginAuto u-maxWidth1032 u-paddingHorizontal20 js-metabarBottom"><nav role="navigation" class="metabar-block metabar-block--below u-flexCenter u-overflowHidden u-height54"><div class="u-flexCenter u-overflowHidden"><div class="u-marginRight40"><a href="https://towardsdatascience.com/?source=logo-lo_sAdmRsl8s2Kf---7f60cf5620c9" class="u-flexCenter js-collectionLogoOrName"><img height="36" width="97" src="./cnn_files/1_5EUO1kUYBthpOCPzRj_l2g.png" alt="Towards Data Science"></a></div><div class="u-overflowHidden u-xs-hide"><ul class="u-textAlignLeft u-noWrap u-overflowX u-height80 u-marginTop40 js-collectionNavItems"><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-science/home">Data Science</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/machine-learning/home">Machine Learning</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/programming/home">Programming</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-visualization/home">Visualization</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/artificial-intelligence/home">AI</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-journalism/home">Journalism</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/editors-picks/home">Picks</a></li><span class="u-borderLeft1 u-baseColor--borderLight"></span><li class="metabar-navItem js-collectionNavItem is-external u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darkenOnHover u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/contribute/home" rel="nofollow noopener" target="_blank">Contribute</a></li></ul></div></div></nav></div></div></div><div class="metabar metabar--spacer js-metabarSpacer u-tintBgColor  u-height119 u-xs-height110"></div><main role="main"><article class=" u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full is-withAccentColors u-marginBottom40" lang="en"><div class="postArticle-content js-postField js-notesSource js-trackPostScrolls" data-post-id="79a07dd44cf9" data-source="post_page" data-collection-id="7f60cf5620c9" data-tracking-context="postPage" data-scroll="native"><section name="5bcc" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h1 name="9707" id="9707" class="graf graf--h3 graf--leading graf--title">Gentle Dive into Math Behind Convolutional Neural&nbsp;Networks</h1><h2 name="3180" id="3180" class="graf graf--h4 graf-after--h3 graf--subtitle">Mysteries of Neural Networks Part&nbsp;V</h2><div class="uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup"><div class="u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@piotr.skalski92?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="11b65705ec0" data-action-type="hover" data-user-id="11b65705ec0" data-collection-slug="towards-data-science" dir="auto"><img src="./cnn_files/1_uLFtOD_rwfKeLDbWIEly8g.jpeg" class="avatar-image u-size50x50" alt="Go to the profile of Piotr Skalski"></a></div><div class="u-flex1 u-paddingLeft15 u-overflowHidden"><div class="u-paddingBottom3"><a class="ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker" href="https://towardsdatascience.com/@piotr.skalski92" data-action="show-user-card" data-action-value="11b65705ec0" data-action-type="hover" data-user-id="11b65705ec0" data-collection-slug="towards-data-science" dir="auto">Piotr Skalski</a><span class="followState js-followState" data-user-id="11b65705ec0"><button class="button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9" data-action-source="post_header_lockup"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--smallest button--dark u-noUserSelect button--withChrome u-accentColor--buttonDark button--follow js-followButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/11b65705ec0" data-action-source="post_header_lockup-11b65705ec0-------------------------follow_byline"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="ui-caption u-noWrapWithEllipsis js-testPostMetaInlineSupplemental"><time datetime="2019-04-12T21:27:18.283Z">Apr 12</time><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="12 min read"></span></div></div></div><figure name="a05a" id="a05a" class="graf graf--figure graf-after--h4"><div class="aspectRatioPlaceholder is-locked" style="max-width: 618px; max-height: 434px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 70.19999999999999%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*k6hOViVXOteTOwaI_nCvqg.gif" data-width="618" data-height="434" data-is-featured="true" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*k6hOViVXOteTOwaI_nCvqg.gif?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="52"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*k6hOViVXOteTOwaI_nCvqg.gif" src="./cnn_files/1_k6hOViVXOteTOwaI_nCvqg.gif"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*k6hOViVXOteTOwaI_nCvqg.gif"></noscript></div></div></figure><p name="4c37" id="4c37" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--figure"><span class="graf-dropCap">A</span>utonomous driving, healthcare or retail are just some of the areas where Computer Vision has allowed us to achieve things that, until recently, were considered impossible. Today the dream of a self driving car or automated grocery store does not sound so futuristic anymore. In fact, we are using Computer Vision every day — when we unlock the phone with our face or automatically retouch photos before posting them on social media. Convolutional Neural Networks are possibly the most crucial building blocks behind this huge successes. This time we are going to broaden our understanding of how neural networks work with ideas specific to CNNs. Be advise, the article will include quite complex math equations, but <strong class="markup--strong markup--p-strong">don’t be discouraged if you are not comfortable with linear algebra and differential calculus</strong>. My goal is not to make you remember those formulas, but to provide you with the intuition of what is happening underneath.</p><figure name="db53" id="db53" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 23.714%;"></div><div class="progressiveMedia js-progressiveMedia is-canvasLoaded is-imageLoaded" data-scroll="native"><img src="./cnn_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe data-width="800" data-height="166" width="700" height="145" data-src="/media/938c9b44baaf2d6b74e18b015897c2c2?postId=79a07dd44cf9" data-media-id="938c9b44baaf2d6b74e18b015897c2c2" data-thumbnail="https://i.embed.ly/1/image?url=http%3A%2F%2Fi1.sndcdn.com%2Fartworks-000518693823-p0sn99-t500x500.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./cnn_files/938c9b44baaf2d6b74e18b015897c2c2.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME data-width="800" data-height="166" width="700" height="145" src="/media/938c9b44baaf2d6b74e18b015897c2c2?postId=79a07dd44cf9" data-media-id="938c9b44baaf2d6b74e18b015897c2c2" data-thumbnail="https://i.embed.ly/1/image?url=http%3A%2F%2Fi1.sndcdn.com%2Fartworks-000518693823-p0sn99-t500x500.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div></figure><p name="285b" id="285b" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">Side notes:</strong> For the first time I decided to enrich my artwork with an audio version and I kindly invite you to listen to it. You will find a link to Soundcloud above. In this article I focus mainly on things typical to CNNs. If you are looking for more general information about deep neural networks I encourage you to read my other posts from <a href="https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba" data-href="https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba" class="markup--anchor markup--p-anchor" target="_blank">this series</a>. As usual, full source code with visualizations and comments can be found on my <a href="https://github.com/SkalskiP/ILearnDeepLearning.py" data-href="https://github.com/SkalskiP/ILearnDeepLearning.py" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GitHub</a>. Let’s start!</p><h4 name="5d03" id="5d03" class="graf graf--h4 graf-after--p">Introduction</h4><p name="34ec" id="34ec" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">In</span> the past we got to know the so-called densely connected neural networks. These are networks whose neurons are divided into groups forming successive layers. Each such unit is connected to every single neuron from the neighboring layers. An example of such an architecture is shown in the figure below.</p><figure name="ebd2" id="ebd2" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 443px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 63.2%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*exGQuaF5oCWTncJYY_lPhw.png" data-width="1521" data-height="962" data-action="zoom" data-action-value="1*exGQuaF5oCWTncJYY_lPhw.png" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*exGQuaF5oCWTncJYY_lPhw.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="46"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*exGQuaF5oCWTncJYY_lPhw.png" src="https://cdn-images-1.medium.com/max/1600/1*exGQuaF5oCWTncJYY_lPhw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*exGQuaF5oCWTncJYY_lPhw.png"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 1.</strong> Densely connected neural network architecture</figcaption></figure><p name="9f85" id="9f85" class="graf graf--p graf-after--figure">This approach works well when we solve classification problem based on a limited set of defined features — for example, we predict a football player’s position based on the statistics he logs during games. However, the situation becomes more complicated when working with photos. Of course, we could treat the brightness of each pixel as a separate feature and pass it on as an input to our dense network. Unfortunately, in order to make it work for a typical smartphone photo, our network would have to contain tens or even hundreds of millions of neurons. On the other hand, we could scale our photo down, but we would lose valuable information in the process. Right away we see that a traditional strategy does nothing for us— we need a new clever way to use as much data as possible, but at the same time reduce the number of necessary calculations and parameters. That’s when CNNs comes into play.</p><h4 name="c689" id="c689" class="graf graf--h4 graf-after--p">Digital photo data structure</h4><p name="ada8" id="ada8" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">L</span>et’s start by taking a minute to explain how digital images are stored. Most of you probably realize that they are actually huge matrices of numbers. Each such number corresponds to the brightness of a single pixel. In the RGB model, the colour image is actually composed of three such matrices corresponding to three colour channels — red, green and blue. In black-and-white images we only need one matrix. Each of these matrices stores values from 0 to 255. This range is a compromise between the efficacy of storing information about the image (256 values fit perfectly in 1 byte) and the sensitivity of the human eye (we distinguish a limited number of shades of the same colour).</p><figure name="65e7" id="65e7" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 466px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.5%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*HPbsBA5BJovt-vrbF1C7Jg.png" data-width="1521" data-height="1012" data-action="zoom" data-action-value="1*HPbsBA5BJovt-vrbF1C7Jg.png" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*HPbsBA5BJovt-vrbF1C7Jg.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="48"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*HPbsBA5BJovt-vrbF1C7Jg.png" src="https://cdn-images-1.medium.com/max/1600/1*HPbsBA5BJovt-vrbF1C7Jg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*HPbsBA5BJovt-vrbF1C7Jg.png"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 2.</strong> Data structure behind digital&nbsp;images</figcaption></figure><h4 name="17a8" id="17a8" class="graf graf--h4 graf-after--figure">Convolution</h4><p name="76da" id="76da" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">K</span>ernel convolution is not only used in CNNs, but is also a key element of many other Computer Vision algorithms.<strong class="markup--strong markup--p-strong"> It is a process where we take a small matrix of numbers (called kernel or filter), we pass it over our image and transform it based on the values from filter. </strong>Subsequent feature map values are calculated according to the following formula, where the input image is denoted by <em class="markup--em markup--p-em">f</em> and our kernel by <em class="markup--em markup--p-em">h</em>. The indexes of rows and columns of the result matrix are marked with <em class="markup--em markup--p-em">m</em> and <em class="markup--em markup--p-em">n</em> respectively.</p><figure name="6e81" id="6e81" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 470px; max-height: 42px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 8.9%;"></div><img class="graf-image" data-image-id="1*EJBQVsY0g6XqBaGgU8hYfA.gif" data-width="470" data-height="42" src="https://cdn-images-1.medium.com/max/1600/1*EJBQVsY0g6XqBaGgU8hYfA.gif"></div></figure><figure name="df5e" id="df5e" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 465px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.5%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*32zCSTBi3giSApz1oQV-zA.gif" data-width="761" data-height="506" data-action="zoom" data-action-value="1*32zCSTBi3giSApz1oQV-zA.gif" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*32zCSTBi3giSApz1oQV-zA.gif?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="48"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*32zCSTBi3giSApz1oQV-zA.gif" src="./cnn_files/1_32zCSTBi3giSApz1oQV-zA.gif"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*32zCSTBi3giSApz1oQV-zA.gif"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 3.</strong> Kernel convolution example</figcaption></figure><p name="aa25" id="aa25" class="graf graf--p graf-after--figure">After placing our filter over a selected pixel, we take each value from kernel and multiply them in pairs with corresponding values from the image. Finally we sum up everything and put the result in the right place in the output feature map. Above we can see how such an operation looks like in micro scale, but what is even more interesting, is what we can achieve by performing it on a full image. Figure 4 shows the results of the convolution with several different filters.</p><figure name="aa75" id="aa75" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 547px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 78.10000000000001%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*TAo3aselJNVwrLLr654Myg.gif" data-width="1600" data-height="1250" data-action="zoom" data-action-value="1*TAo3aselJNVwrLLr654Myg.gif" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*TAo3aselJNVwrLLr654Myg.gif?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="57"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*TAo3aselJNVwrLLr654Myg.gif" src="./cnn_files/1_TAo3aselJNVwrLLr654Myg.gif"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*TAo3aselJNVwrLLr654Myg.gif"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 4.</strong> Finding edges with kernel convolution [<a href="https://www.maxpixel.net/Idstein-Historic-Center-Truss-Facade-Germany-3748512" data-href="https://www.maxpixel.net/Idstein-Historic-Center-Truss-Facade-Germany-3748512" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Original Image</a>]</figcaption></figure><h4 name="1065" id="1065" class="graf graf--h4 graf-after--figure">Valid and Same Convolution</h4><p name="041d" id="041d" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">As</span> we have seen in Figure 3, when we perform convolution over the 6x6 image with a 3x3 kernel, we get a 4x4 feature map. This is because there are only 16 unique positions where we can place our filter inside this picture. <strong class="markup--strong markup--p-strong">Since our image shrinks every time we perform convolution, we can do it only a limited number of times, before our image disappears completely. What’s more, if we look at how our kernel moves through the image we see that the impact of the pixels located on the outskirts is much smaller than those in the center of image. </strong>This way we lose some of the information contained in the picture. Below you can see how the position of the pixel changes its influence on the feature map.</p><figure name="eb35" id="eb35" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 465px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.5%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*P1vkUXqHJbAbUQWDrxg8rA.gif" data-width="1065" data-height="708" data-action="zoom" data-action-value="1*P1vkUXqHJbAbUQWDrxg8rA.gif" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*P1vkUXqHJbAbUQWDrxg8rA.gif?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="48"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*P1vkUXqHJbAbUQWDrxg8rA.gif" src="https://cdn-images-1.medium.com/max/1600/1*P1vkUXqHJbAbUQWDrxg8rA.gif"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*P1vkUXqHJbAbUQWDrxg8rA.gif"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 5.</strong> Impact of pixel&nbsp;position</figcaption></figure><p name="4011" id="4011" class="graf graf--p graf-after--figure">To solve both of these problems we can pad our image with an additional border. For example, if we use 1px padding, we increase the size of our photo to 8x8, so that output of the convolution with the 3x3 filter will be 6x6. Usually in practice we fill in additional padding with zeroes. Depending on whether we use padding or not, we are dealing with two types of convolution — Valid and Same. Naming is quite unfortunate, so for the sake of clarity: <strong class="markup--strong markup--p-strong">Valid — means that we use the original image, Same — we use the border around it</strong>, so that the images at the input and output are the same size. In the second case, the padding width, should meet the following equation, where <em class="markup--em markup--p-em">p</em> is padding and <em class="markup--em markup--p-em">f</em> is the filter dimension (usually odd).</p><figure name="e7fd" id="e7fd" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 99px; max-height: 46px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 46.5%;"></div><img class="graf-image" data-image-id="1*RT4wahrezNLWl4DeqWDOjw.gif" data-width="99" data-height="46" src="https://cdn-images-1.medium.com/max/1600/1*RT4wahrezNLWl4DeqWDOjw.gif"></div></figure><h4 name="afbd" id="afbd" class="graf graf--h4 graf-after--figure">Strided Convolution</h4><figure name="cc9d" id="cc9d" class="graf graf--figure graf-after--h4"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 517px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 73.9%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*itcofCIVsGe7rBmciJcmVw.gif" data-width="1065" data-height="787" data-action="zoom" data-action-value="1*itcofCIVsGe7rBmciJcmVw.gif" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*itcofCIVsGe7rBmciJcmVw.gif?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="55"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*itcofCIVsGe7rBmciJcmVw.gif" src="https://cdn-images-1.medium.com/max/1600/1*itcofCIVsGe7rBmciJcmVw.gif"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*itcofCIVsGe7rBmciJcmVw.gif"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 6.</strong> Example of strided convolution</figcaption></figure><p name="5c5f" id="5c5f" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--figure"><span class="graf-dropCap">In</span> previous examples, we always shifted our kernel by one pixel. However, step length can also be treated as one of convolution layer hyperparameters. In Figure 6, we can see how the convolution looks like if we use larger stride. When designing our CNN architecture, we can decide to increase the step if we want the receptive fields to overlap less or if we want smaller spatial dimensions of our feature map. The dimensions of the output matrix - taking into account padding and stride - can be calculated using the following formula.</p><figure name="e6b3" id="e6b3" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 258px; max-height: 54px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 20.9%;"></div><img class="graf-image" data-image-id="1*HoOLVDujrz1TKJJ6ijR6Bw.gif" data-width="258" data-height="54" src="https://cdn-images-1.medium.com/max/1600/1*HoOLVDujrz1TKJJ6ijR6Bw.gif"></div></figure><h4 name="47de" id="47de" class="graf graf--h4 graf-after--figure">The transition to the third dimension</h4><p name="cb02" id="cb02" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">C</span>onvolution over volume is a very important concept, which will allow us not only to work with color images, but even more importantly to apply multiple filters within a single layer. <strong class="markup--strong markup--p-strong">The first important rule is that the filter and the image you want to apply it to, must have the same number of channels.</strong> Basically, we proceed very much like in the example from Figure 3, nevertheless this time we multiply the pairs of values from the three-dimensional space.<strong class="markup--strong markup--p-strong"> If we want use multiple filters on the same image, we carry out the convolution for each of them separately, stack the results one on top of the other and combine them into a whole.</strong> The dimensions of the received tensor (as our 3D matrix can be called) meet the following equation, in which: <em class="markup--em markup--p-em">n</em> — image size, <em class="markup--em markup--p-em">f</em> — filter size, <em class="markup--em markup--p-em">nc</em> — number of channels in the image, <em class="markup--em markup--p-em">p </em>—used padding,<em class="markup--em markup--p-em"> s</em> — used stride, <em class="markup--em markup--p-em">nf </em>— number of filters.</p><figure name="4f05" id="4f05" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 647px; max-height: 54px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 8.3%;"></div><img class="graf-image" data-image-id="1*oto8zpybb-uWB_7Uu7Nk8w.gif" data-width="647" data-height="54" src="https://cdn-images-1.medium.com/max/1600/1*oto8zpybb-uWB_7Uu7Nk8w.gif"></div></figure><figure name="5783" id="5783" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 443px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 63.3%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*Ukb2msCjU3G5eS4a45f-lg.png" data-width="1522" data-height="964" data-action="zoom" data-action-value="1*Ukb2msCjU3G5eS4a45f-lg.png" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*Ukb2msCjU3G5eS4a45f-lg.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="47"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*Ukb2msCjU3G5eS4a45f-lg.png" src="https://cdn-images-1.medium.com/max/1600/1*Ukb2msCjU3G5eS4a45f-lg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*Ukb2msCjU3G5eS4a45f-lg.png"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 7.</strong> Convolution over&nbsp;volume</figcaption></figure><h4 name="6ef9" id="6ef9" class="graf graf--h4 graf-after--figure">Convolution Layers</h4><p name="ea7c" id="ea7c" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">T</span>he time has finally come to use everything we have learned today and to build a single layer of our CNN. Our methodology is almost identical to the one we used for densely connected neural networks, the only difference is that instead of using a simple matrix multiplication, this time we will use the convolution. Forward propagation consists of two steps. The first one is to calculate the intermediate value<strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em"> </em>Z</strong>, which is obtained as a result of the convolution of the input data from the previous layer with <strong class="markup--strong markup--p-strong">W</strong> tensor (containing filters), and then adding bias <strong class="markup--strong markup--p-strong">b</strong>. The second is the application of a non-linear activation function to our intermediate value (our activation is denoted by g). Fans of matrix equations will find appropriate mathematical formulas below. If any of the operations in question is not clear to you, I highly recommend my <a href="https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba" data-href="https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba" class="markup--anchor markup--p-anchor" target="_blank">previous article</a>, in which I discuss in detail what is happening inside densely connected neural networks. By the way, on illustration below you can see a small visualization, describing the dimensions of tensors used in equation.</p><figure name="9f44" id="9f44" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 337px; max-height: 19px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 5.6000000000000005%;"></div><img class="graf-image" data-image-id="1*fkfVP6I7QXdxlnnCsxYsfA.gif" data-width="337" data-height="19" src="https://cdn-images-1.medium.com/max/1600/1*fkfVP6I7QXdxlnnCsxYsfA.gif"></div></figure><figure name="bc73" id="bc73" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 465px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.4%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*T4FpV497IYNinpT0mzlaLA.png" data-width="1522" data-height="1011" data-action="zoom" data-action-value="1*T4FpV497IYNinpT0mzlaLA.png" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*T4FpV497IYNinpT0mzlaLA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="48"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*T4FpV497IYNinpT0mzlaLA.png" src="https://cdn-images-1.medium.com/max/1600/1*T4FpV497IYNinpT0mzlaLA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*T4FpV497IYNinpT0mzlaLA.png"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 8.</strong> Tensors dimensions</figcaption></figure><h4 name="5260" id="5260" class="graf graf--h4 graf-after--figure">Connections Cutting and Parameters Sharing</h4><p name="67a9" id="67a9" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">At</span> the beginning of the article I mentioned that densely connected neural networks are poor at working with images, due to the huge number of parameters that would need to be learned. Now that we understand what convolution is all about, let’s consider how it allows us to optimize the calculations. On the Figure below, the 2D convolution has been visualized in a slightly different way — neurons marked with numbers 1–9 form the input layer that receives brightness of subsequent pixels, while units A-D denotes calculated feature map elements. Last but not least, I-IV are the subsequent values from kernel — these must be learned.</p><figure name="a6e6" id="a6e6" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 502px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 71.7%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*6S1ltWsTUIdULzRxqueWiA.gif" data-width="1260" data-height="904" data-action="zoom" data-action-value="1*6S1ltWsTUIdULzRxqueWiA.gif" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*6S1ltWsTUIdULzRxqueWiA.gif?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="53"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*6S1ltWsTUIdULzRxqueWiA.gif" src="https://cdn-images-1.medium.com/max/1600/1*6S1ltWsTUIdULzRxqueWiA.gif"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*6S1ltWsTUIdULzRxqueWiA.gif"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 9.</strong> Connections cutting and parameters sharing</figcaption></figure><p name="b35f" id="b35f" class="graf graf--p graf-after--figure">Now, let’s focus on the two very important attributes of convolution layers. <strong class="markup--strong markup--p-strong">First of all, you can see that not all neurons in the two consecutive layers are connected to each other. </strong>For example, unit 1 only affects the value of A. <strong class="markup--strong markup--p-strong">Secondly, we see that some neurons share the same weights. </strong>Both of these properties mean that we have much less parameters to learn. By the way, it is worth noting that a single value from the filter affects every element of the feature map — it will be crucial in the context of backpropagation.</p><h4 name="87a8" id="87a8" class="graf graf--h4 graf-after--p">Convolutional Layer Backpropagation</h4><p name="96b1" id="96b1" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">A</span>nyone who has ever tried to code their own neural network from scratch knows, that forward propagation is less than half the success. The real fun starts when you want to go back. Nowadays, we don’t need to bother with backpropagation — deep learning frameworks do it for us, but I feel it’s worth knowing what’s going on under the hood. <strong class="markup--strong markup--p-strong">Just like in densely connected neural networks, our goal is to calculate derivatives and later use them to update the values of our parameters in a process called gradient descent.</strong></p><p name="360d" id="360d" class="graf graf--p graf-after--p">In our calculations we will use a chain rule — which I mentioned in previous articles.<strong class="markup--strong markup--p-strong"> We want to assess the influence of the change in the parameters on the resulting features map, and subsequently on the final result.</strong> Before we start to go into the details, let us agree on the mathematical notation that we will use — in order to make my life easier, I will abandon the full notation of the partial derivative in favour of the shortened one visible below. But remember, that when I use this notation, I will always mean the partial derivative of the cost function.</p><figure name="18e8" id="18e8" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 496px; max-height: 42px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 8.5%;"></div><img class="graf-image" data-image-id="1*3k9R6aUwekXXEHVrGbMitw.gif" data-width="496" data-height="42" src="https://cdn-images-1.medium.com/max/1600/1*3k9R6aUwekXXEHVrGbMitw.gif"></div></figure><figure name="ae45" id="ae45" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 373px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 53.300000000000004%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*1ma11FU4okzC-csMEAU0kQ.png" data-width="1351" data-height="720" data-action="zoom" data-action-value="1*1ma11FU4okzC-csMEAU0kQ.png" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*1ma11FU4okzC-csMEAU0kQ.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="38"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*1ma11FU4okzC-csMEAU0kQ.png" src="https://cdn-images-1.medium.com/max/1600/1*1ma11FU4okzC-csMEAU0kQ.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*1ma11FU4okzC-csMEAU0kQ.png"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 10.</strong> Input and output data for a single convolution layer in forward and backward propagation</figcaption></figure><p name="2a51" id="2a51" class="graf graf--p graf-after--figure">Our task is to calculate <strong class="markup--strong markup--p-strong">dW[l]</strong> and <strong class="markup--strong markup--p-strong">db[l] -</strong> which are derivatives associated with parameters of current layer, as well as the value of <strong class="markup--strong markup--p-strong">dA[ l -1] </strong>-<strong class="markup--strong markup--p-strong"> </strong>which will be passed to the previous layer. As shown in Figure 10, we receive the <strong class="markup--strong markup--p-strong">dA[l] </strong>as the input. Of course, the dimensions of tensors <strong class="markup--strong markup--p-strong">dW</strong> and <strong class="markup--strong markup--p-strong">W</strong>, <strong class="markup--strong markup--p-strong">db</strong> and <strong class="markup--strong markup--p-strong">b</strong> as well as <strong class="markup--strong markup--p-strong">dA</strong> and <strong class="markup--strong markup--p-strong">A</strong> respectively are the same. The first step is to obtain the intermediate value <strong class="markup--strong markup--p-strong">dZ[l]</strong> by applying a derivative of our activation function to our input tensor. According to the chain rule, the result of this operation will be used later.</p><figure name="740f" id="740f" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 185px; max-height: 22px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 11.899999999999999%;"></div><img class="graf-image" data-image-id="1*UBilkUfJ6OCUpWAJlPsavg.gif" data-width="185" data-height="22" src="https://cdn-images-1.medium.com/max/1600/1*UBilkUfJ6OCUpWAJlPsavg.gif"></div></figure><p name="a2ed" id="a2ed" class="graf graf--p graf-after--figure">Now, we need to deal with backward propagation of the convolution itself, and in order to achieve this goal we will utilise a matrix operation called full convolution — which is visualised below. Note that during this process we use the kernel, which we previously rotated by 180 degrees. This operation can be described by the following formula, where the filter is denoted by <strong class="markup--strong markup--p-strong">W</strong>, and <strong class="markup--strong markup--p-strong">dZ[m,n]</strong> is a scalar that belongs to a partial derivative obtained from the previous layer.</p><figure name="38c0" id="38c0" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 243px; max-height: 53px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 21.8%;"></div><img class="graf-image" data-image-id="1*soIA9mwFw1UMaU2M8eAGEA.gif" data-width="243" data-height="53" src="https://cdn-images-1.medium.com/max/1600/1*soIA9mwFw1UMaU2M8eAGEA.gif"></div></figure><figure name="d4d8" id="d4d8" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 465px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.5%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*SYJpq-rOn6idEYbljdwT7w.gif" data-width="1065" data-height="708" data-action="zoom" data-action-value="1*SYJpq-rOn6idEYbljdwT7w.gif" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*SYJpq-rOn6idEYbljdwT7w.gif?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="48"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*SYJpq-rOn6idEYbljdwT7w.gif" src="https://cdn-images-1.medium.com/max/1600/1*SYJpq-rOn6idEYbljdwT7w.gif"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*SYJpq-rOn6idEYbljdwT7w.gif"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 11.</strong> Full convolution</figcaption></figure><h4 name="8497" id="8497" class="graf graf--h4 graf-after--figure">Pooling Layers</h4><p name="8427" id="8427" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">B</span>esides convolution layers, CNNs very often use so-called pooling layers. They are used primarily to reduce the size of the tensor and speed up calculations. This layers are simple - we need to divide our image into different regions, and then perform some operation for each of those parts. For example, for the Max Pool Layer, we select a maximum value from each region and put it in the corresponding place in the output. As in the case of the convolution layer, we have two hyperparameters available — filter size and stride. Last but not least, if you are performing pooling for a multi-channel image, the pooling for each channel should be done separately.</p><figure name="94df" id="94df" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 465px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.5%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*qImgD2KGZw7ETjw3mOxNyg.gif" data-width="1065" data-height="708" data-action="zoom" data-action-value="1*qImgD2KGZw7ETjw3mOxNyg.gif" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*qImgD2KGZw7ETjw3mOxNyg.gif?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="48"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*qImgD2KGZw7ETjw3mOxNyg.gif" src="https://cdn-images-1.medium.com/max/1600/1*qImgD2KGZw7ETjw3mOxNyg.gif"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*qImgD2KGZw7ETjw3mOxNyg.gif"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 12.</strong> Max pooling&nbsp;example</figcaption></figure><h4 name="ddab" id="ddab" class="graf graf--h4 graf-after--figure">Pooling Layers Backpropagation</h4><p name="461f" id="461f" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">In</span> this article we will discuss only max pooling backpropagation, but the rules that we will learn — with minor adjustments — are applicable to all types of pooling layers. Since in layers of this type, we don’t have any parameters that we would have to update, our task is only to distribute gradiwents appropriately. As we remember, in the forward propagation for max pooling, we select the maximum value from each region and transfer them to the next layer. It is therefore clear that during back propagation, the gradient should not affect elements of the matrix that were not included in the forward pass. In practice, this is achieved by creating a mask that remembers the position of the values used in the first phase, which we can later utilize to transfer the gradients.</p><figure name="4258" id="4258" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 600px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 85.7%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*jhW0G_vJsYCQpphu50yj2Q.gif" data-width="1065" data-height="913" data-action="zoom" data-action-value="1*jhW0G_vJsYCQpphu50yj2Q.gif" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/60/1*jhW0G_vJsYCQpphu50yj2Q.gif?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="63"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*jhW0G_vJsYCQpphu50yj2Q.gif" src="https://cdn-images-1.medium.com/max/1600/1*jhW0G_vJsYCQpphu50yj2Q.gif"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*jhW0G_vJsYCQpphu50yj2Q.gif"></noscript></div></div><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Figure 13.</strong> Max pooling backward&nbsp;pass</figcaption></figure><h4 name="972f" id="972f" class="graf graf--h4 graf-after--figure">Conclusion</h4><p name="3554" id="3554" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--h4"><span class="graf-dropCap">C</span>ongratulations if you managed to get here. Big thanks for the time spent reading this article. If you liked the post, consider sharing it with your friend, or two friends or five friends. If you have noticed any mistakes in the way of thinking, formulas, animations or code, please let me know.</p><p name="8e38" id="8e38" class="graf graf--p graf-after--p graf--trailing">This article is another part of the “Mysteries of Neural Networks” series, if you haven’t had the opportunity yet, read the <a href="https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a" data-href="https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">other articles</a>. Also, if you like my job so far, follow me on <a href="https://twitter.com/PiotrSkalski92" data-href="https://twitter.com/PiotrSkalski92" class="markup--anchor markup--p-anchor" rel="noopener nofollow noopener noopener" target="_blank">Twitter</a> and <a href="https://medium.com/@piotr.skalski92" data-href="https://medium.com/@piotr.skalski92" class="markup--anchor markup--p-anchor" target="_blank">Medium</a> and see other projects I’m working on, on <a href="https://github.com/SkalskiP" data-href="https://github.com/SkalskiP" class="markup--anchor markup--p-anchor" rel="noopener nofollow noopener noopener" target="_blank">GitHub</a> and <a href="https://www.kaggle.com/skalskip" data-href="https://www.kaggle.com/skalskip" class="markup--anchor markup--p-anchor" rel="noopener nofollow noopener noopener" target="_blank">Kaggle</a>. Stay curious!</p></div></div></section><section name="4660" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--outsetRow" data-paragraph-count="3"><figure name="cd82" id="cd82" class="graf graf--figure graf--layoutOutsetRow is-partialWidth graf--leading" style="width: 33.333%;" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 28.599999999999998%;"></div><a href="https://github.com/SkalskiP/ILearnDeepLearning.py" data-href="https://github.com/SkalskiP/ILearnDeepLearning.py" class="graf-imageAnchor" data-action="image-link" data-action-observe-only="true" rel="noopener" target="_blank"><img class="graf-image" data-image-id="1*0ftx4YXKIvvHjGPovjkanw.png" data-width="350" data-height="100" src="https://cdn-images-1.medium.com/max/800/1*0ftx4YXKIvvHjGPovjkanw.png"></a></div></figure><figure name="b1d0" id="b1d0" class="graf graf--figure graf--layoutOutsetRowContinue is-partialWidth graf-after--figure" style="width: 33.333%;" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 28.599999999999998%;"></div><a href="https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795?source=---------5------------------" data-href="https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795?source=---------5------------------" class="graf-imageAnchor" data-action="image-link" data-action-observe-only="true"><img class="graf-image" data-image-id="1*GFJaJiJ7TN5GxroF6G-xjQ.png" data-width="350" data-height="100" src="https://cdn-images-1.medium.com/max/800/1*GFJaJiJ7TN5GxroF6G-xjQ.png"></a></div></figure><figure name="860b" id="860b" class="graf graf--figure graf--layoutOutsetRowContinue is-partialWidth graf-after--figure graf--trailing" style="width: 33.333%;" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 28.599999999999998%;"></div><a href="https://twitter.com/PiotrSkalski92" data-href="https://twitter.com/PiotrSkalski92" class="graf-imageAnchor" data-action="image-link" data-action-observe-only="true" rel="noopener" target="_blank"><img class="graf-image" data-image-id="1*-ObBrMMfnVFCG5u--QOZ6g.png" data-width="350" data-height="100" src="https://cdn-images-1.medium.com/max/800/1*-ObBrMMfnVFCG5u--QOZ6g.png"></a></div></figure></div></div></section></div><footer class="u-paddingTop10"><div class="container u-maxWidth740"><div class="row"><div class="col u-size12of12"></div></div><div class="row"><div class="col u-size12of12 js-postTags"><div class="u-paddingBottom10"><ul class="tags tags--postTags tags--borderless"><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/machine-learning?source=post" data-action-source="post" data-collection-slug="towards-data-science">Machine Learning</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/deep-learning?source=post" data-action-source="post" data-collection-slug="towards-data-science">Deep Learning</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/neural-networks?source=post" data-action-source="post" data-collection-slug="towards-data-science">Neural Networks</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/towards-data-science?source=post" data-action-source="post" data-collection-slug="towards-data-science">Towards Data Science</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/data-science?source=post" data-action-source="post" data-collection-slug="towards-data-science">Data Science</a></li></ul></div></div></div><div class="postActions js-postActionsFooter "><div class="u-flexCenter"><div class="u-flex1"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="79a07dd44cf9" data-is-icon-29px="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_actions_footer-----79a07dd44cf9---------------------clap_footer" data-clap-string-singular="clap" data-clap-string-plural="claps"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboardingcollection" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/79a07dd44cf9" data-action-source="post_actions_footer-----79a07dd44cf9---------------------clap_footer" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Springu-backgroundGrayLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="79a07dd44cf9"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft16"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-textColorDarker" data-action="show-recommends" data-action-value="79a07dd44cf9">2.1K claps</button><span class="u-xs-hide"></span></span></div></div><div class="buttonSet u-flex0"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12" href="https://medium.com/p/79a07dd44cf9/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></span></a><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12" href="https://medium.com/p/79a07dd44cf9/share/facebook" title="Share on Facebook" aria-label="Share on Facebook" target="_blank" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></span></a><button class="button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show u-marginRight10" title="Share this story on Twitter or Facebook" aria-label="Share this story on Twitter or Facebook" data-action="show-share-popover" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--share svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706" fill-rule="evenodd"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" data-action="scroll-to-responses" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal u-marginRight12" data-action="scroll-to-responses">2</button><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/79a07dd44cf9" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon js-moreActionsButton" title="More actions" aria-label="More actions" data-action="more-actions"><span class="svgIcon svgIcon--more svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="-480.5 272.5 21 21"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></span></button></div></div></div></div><div class="u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer"><div class="row js-postFooterInfo"><div class="col u-size6of12 u-xs-size12of12"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser"><div class="u-marginLeft20 u-floatRight"><span class="followState js-followState" data-user-id="11b65705ec0"><button class="button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9" data-action-source="footer_card"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/11b65705ec0" data-action-source="footer_card-11b65705ec0-------------------------follow_footer"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="u-tableCell"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@piotr.skalski92?source=footer_card" title="Go to the profile of Piotr Skalski" aria-label="Go to the profile of Piotr Skalski" data-action-source="footer_card" data-user-id="11b65705ec0" data-collection-slug="towards-data-science" dir="auto"><img src="./cnn_files/1_uLFtOD_rwfKeLDbWIEly8g(1).jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Piotr Skalski"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://towardsdatascience.com/@piotr.skalski92" property="cc:attributionName" title="Go to the profile of Piotr Skalski" aria-label="Go to the profile of Piotr Skalski" rel="author cc:attributionUrl" data-user-id="11b65705ec0" data-collection-slug="towards-data-science" dir="auto">Piotr Skalski</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">#ComputerScience student and Frontend developer at day #React #JavaScript, #MachineLearning enthusiast at night #Kaggle, #Python, #TensorFlow.js</p></div></li></div><div class="col u-size6of12 u-xs-size12of12 u-xs-marginTop30"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardCollection"><div class="u-marginLeft20 u-floatRight"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/towards-data-science" data-action-source="footer_card----7f60cf5620c9----------------------follow_footer" data-collection-id="7f60cf5620c9"><span class="button-label  js-buttonLabel">Follow</span></button></div><div class="u-tableCell "><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://towardsdatascience.com/?source=footer_card" title="Go to Towards Data Science" aria-label="Go to Towards Data Science" data-action-source="footer_card" data-collection-slug="towards-data-science"><img src="./cnn_files/1_F0LADxTtsKOgmPa-_7iUEQ.jpeg" class="avatar-image u-size60x60" alt="Towards Data Science"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://towardsdatascience.com/?source=footer_card" rel="collection" data-action-source="footer_card" data-collection-slug="towards-data-science">Towards Data Science</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Sharing concepts, ideas, and codes.</p><div class="buttonSet"></div></div></li></div></div></div><div class="js-postFooterPlacements" data-post-id="79a07dd44cf9" data-collection-id="7f60cf5620c9" data-scroll="native"></div><div class="u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper" data-action-scope="_actionscope_5"><div class="container u-maxWidth740"><div class="responsesStreamWrapper u-maxWidth640 u-hide js-responsesStreamWrapper"><div class="container responsesStream-title u-paddingTop15"><div class="row"><header class="heading"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title heading-title--semibold">Responses</span></div></div></header></div></div><div class="responsesStream-editor cardChromeless u-marginBottom20 u-paddingLeft20 u-paddingRight20 js-responsesStreamEditor"><div class="u-paddingTop30 u-paddingBottom30 u-paddingLeft0 u-paddingRight0 u-borderBottomLightest js-responsesLoggedOutPrompt"><button class="button button--chromeless is-touchIconBlackPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--withIconAndLabel button--loggedOutPrompt" data-action="sign-up-prompt" data-redirect="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9#--respond" data-skip-onboarding="true" data-action-source="logged_out_response_prompt--------------------------respond_box"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span><span class="button-label  js-buttonLabel">Write a response…</span></button></div></div><div class="responsesStream js-responsesStream"></div><div class="container u-hide js-showOtherResponses"><div class="row"><button class="button button--primary button--withChrome u-accentColor--buttonNormal responsesStream-showOtherResponses cardChromeless u-width100pct u-marginVertical20 u-heightAuto" data-action="show-other-responses">Show all responses</button></div></div><div class="responsesStream js-responsesStreamOther"></div></div></div></div><div class="supplementalPostContent js-heroPromo"></div></footer></article></main><aside class="u-marginAuto u-maxWidth1032 js-postLeftSidebar"><div class="u-foreground u-top0 u-sm-hide js-postShareWidget u-fixed u-transition--fadeOut300" data-scroll="fixed" style="transform: translateY(150px);"><ul><li class="u-marginVertical10"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="79a07dd44cf9" data-is-icon-29px="true" data-has-recommend-list="true" data-source="post_share_widget-----79a07dd44cf9---------------------clap_sidebar"><div class="u-relative u-foreground"><button class="button button--primary button--large button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/79a07dd44cf9" data-action-source="post_share_widget-----79a07dd44cf9---------------------clap_sidebar" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.739 1l.761 2.966L15.261 1z"></path><path d="M16.815 4.776l1.84-2.551-1.43-.471z"></path><path d="M10.378 2.224l1.84 2.551-.408-3.022z"></path><path d="M22.382 22.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L6.11 15.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L8.43 9.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L20.628 15c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM12.99 6.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.738 1l.762 2.966L15.262 1z"></path><path d="M18.634 2.224l-1.432-.47-.408 3.022z"></path><path d="M11.79 1.754l-1.431.47 1.84 2.552z"></path><path d="M24.472 14.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M14.58 10.887c-.156-.83.096-1.569.692-2.142L12.78 6.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M17.812 10.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L9.2 7.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L7.046 9.54 5.802 8.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394l1.241 1.241 4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L4.89 11.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C21.74 20.8 22.271 18 20.62 14.982l-2.809-4.942z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton" data-action="show-recommends" data-action-value="79a07dd44cf9">2.1K</button></span></div></li><li class="u-marginVertical10 u-marginLeft3"><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/79a07dd44cf9" data-action-source="post_share_widget-----79a07dd44cf9---------------------bookmark_sidebar"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button></li><li class="u-marginVertical10 u-marginLeft3"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless" href="https://medium.com/p/79a07dd44cf9/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action-source="post_share_widget"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></span></a></li><li class="u-marginVertical10 u-marginLeft3"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless" href="https://medium.com/p/79a07dd44cf9/share/facebook" title="Share on Facebook" aria-label="Share on Facebook" target="_blank" data-action-source="post_share_widget"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></span></a></li></ul></div></aside><div class="u-fixed u-bottom0 u-width100pct u-backgroundWhite u-boxShadowTop u-borderBox u-paddingTop10 u-paddingBottom10 u-zIndexMetabar u-xs-hide js-stickyFooter"><div class="u-maxWidth700 u-marginAuto u-flexCenter"><div class="u-fontSize16 u-flex1 u-flexCenter"><div class="u-flex0 u-inlineBlock u-paddingRight20"><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://towardsdatascience.com/" title="Go to Towards Data Science" aria-label="Go to Towards Data Science" data-collection-slug="towards-data-science"><img src="./cnn_files/1_F0LADxTtsKOgmPa-_7iUEQ(1).jpeg" class="avatar-image avatar-image--smaller" alt="Towards Data Science"></a></div><div class="u-flex1 u-inlineBlock">Never miss a story from<strong> Towards Data Science</strong>, when you sign up for Medium. <a class="link u-baseColor--link link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@Medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg" data-action-source="sticky_footer">Learn more</a></div></div><div class="u-marginLeft50"><button class="button button--primary button--dark is-active u-noUserSelect button--withChrome u-accentColor--buttonDark u-uiTextSemibold u-textUppercase u-fontSize12 button--followCollection js-followCollectionButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/towards-data-science" data-action-source="sticky_footer----7f60cf5620c9----------------------follow_metabar"><span class="button-label  button-defaultState js-buttonLabel">Get updates</span><span class="button-label button-activeState">Get updates</span></button></div></div></div><style class="js-collectionStyle">
.u-accentColor--borderLight {border-color: #668AAA !important;}
.u-accentColor--borderNormal {border-color: #668AAA !important;}
.u-accentColor--borderDark {border-color: #5A7690 !important;}
.u-accentColor--iconLight .svgIcon,.u-accentColor--iconLight.svgIcon {fill: #668AAA !important;}
.u-accentColor--iconNormal .svgIcon,.u-accentColor--iconNormal.svgIcon {fill: #668AAA !important;}
.u-accentColor--iconDark .svgIcon,.u-accentColor--iconDark.svgIcon {fill: #5A7690 !important;}
.u-accentColor--textNormal {color: #5A7690 !important;}
.u-accentColor--hoverTextNormal:hover {color: #5A7690 !important;}
.u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #546C83 !important;}
.u-accentColor--textDark {color: #546C83 !important;}
.u-accentColor--backgroundLight {background-color: #668AAA !important;}
.u-accentColor--backgroundNormal {background-color: #668AAA !important;}
.u-accentColor--backgroundDark {background-color: #5A7690 !important;}
.u-accentColor--buttonDark {border-color: #5A7690 !important; color: #546C83 !important;}
.u-accentColor--buttonDark:hover {border-color: #546C83 !important;}
.u-accentColor--buttonDark .icon:before,.u-accentColor--buttonDark .svgIcon{color: #5A7690 !important; fill: #5A7690 !important;}
.u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #668AAA !important; color: #5A7690 !important;}
.u-accentColor--buttonNormal:hover {border-color: #5A7690 !important;}
.u-accentColor--buttonNormal .icon:before,.u-accentColor--buttonNormal .svgIcon{color: #668AAA !important; fill: #668AAA !important;}
.u-accentColor--buttonNormal.button--filled .icon:before,.u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonDark.button--filled,.u-accentColor--buttonDark.button--withChrome.is-active,.u-accentColor--fillWhenActive.is-active {background-color: #5A7690 !important; border-color: #5A7690 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #668AAA !important; border-color: #668AAA !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--user,.postArticle.is-withAccentColors .markup--query {color: #5A7690 !important;}.u-tintBgColor {background-color: rgba(53, 88, 118, 1) !important;}.u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(53, 88, 118, 1) 0%, rgba(53, 88, 118, 0) 100%) !important;}.u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(53, 88, 118, 0) 0%, rgba(53, 88, 118, 1) 100%) !important;}
.u-tintSpectrum .u-baseColor--borderLight {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--borderNormal {border-color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--borderDark {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--iconLight .svgIcon,.u-tintSpectrum .u-baseColor--iconLight.svgIcon {fill: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--iconNormal .svgIcon,.u-tintSpectrum .u-baseColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--iconDark .svgIcon,.u-tintSpectrum .u-baseColor--iconDark.svgIcon {fill: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--textNormal {color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--textDark {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--textDarker {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--backgroundLight {background-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--backgroundNormal {background-color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--backgroundDark {background-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonLight {border-color: #9FB3C6 !important; color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonLight:hover {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonLight .icon:before,.u-tintSpectrum .u-baseColor--buttonLight .svgIcon {color: #9FB3C6 !important; fill: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark:hover {border-color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark .icon:before,.u-tintSpectrum .u-baseColor--buttonDark .svgIcon {color: #E9F1FA !important; fill: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonNormal {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--buttonNormal:hover {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonNormal .icon:before,.u-tintSpectrum .u-baseColor--buttonNormal .svgIcon {color: #C5D2E1 !important; fill: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--buttonDark.button--filled,.u-tintSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-baseColor--buttonNormal.button--filled,.u-tintSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-baseColor--link {color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--darken:active {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:active {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darker {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: #9FB3C6;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: #9FB3C6;}
.u-tintSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: #9FB3C6;}
.u-tintSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: #FBFFFF !important;}
.u-tintSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-h1,.u-tintSpectrum  .ui-h2,.u-tintSpectrum  .ui-h3,.u-tintSpectrum  .ui-h4,.u-tintSpectrum  .ui-brand1,.u-tintSpectrum  .ui-brand2,.u-tintSpectrum  .ui-captionStrong {color: #FBFFFF !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-body,.u-tintSpectrum  .ui-caps {color: #FBFFFF !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-summary,.u-tintSpectrum  .ui-caption {color: #9FB3C6 !important; fill: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--borderLight {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--borderNormal {border-color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--borderDark {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--iconLight .svgIcon,.u-tintSpectrum .u-accentColor--iconLight.svgIcon {fill: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--iconNormal .svgIcon,.u-tintSpectrum .u-accentColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--iconDark .svgIcon,.u-tintSpectrum .u-accentColor--iconDark.svgIcon {fill: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--textNormal {color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--hoverTextNormal:hover {color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--textDark {color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--backgroundLight {background-color: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--backgroundNormal {background-color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--backgroundDark {background-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark:hover {border-color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark .icon:before,.u-tintSpectrum .u-accentColor--buttonDark .svgIcon{color: #E9F1FA !important; fill: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:hover {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonNormal .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal .svgIcon{color: #C5D2E1 !important; fill: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonDark.button--filled,.u-tintSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-tintSpectrum .u-accentColor--fillWhenActive.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-tintSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .postArticle.is-withAccentColors .markup--user,.u-tintSpectrum .postArticle.is-withAccentColors .markup--query {color: #C5D2E1 !important;}
.u-accentColor--highlightFaint {background-color: rgba(233, 242, 253, 1) !important;}
.u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(200, 228, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--quote.is-other {background-color: rgba(233, 242, 253, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(233, 242, 253, 1), rgba(233, 242, 253, 1));}
.postArticle.is-withAccentColors .markup--quote.is-me {background-color: rgba(215, 235, 254, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(215, 235, 254, 1), rgba(215, 235, 254, 1));}
.postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}
.postArticle.is-withAccentColors .markup--quote.is-selected {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}
.postArticle.is-withAccentColors .markup--highlight {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}.u-baseColor--iconNormal.avatar-halo {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}</style><style class="js-collectionStyleConstant">.u-imageBgColor {background-color: rgba(0, 0, 0, 0.24705882352941178);}
.u-imageSpectrum .u-baseColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconLight .svgIcon,.u-imageSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--iconNormal .svgIcon,.u-imageSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconDark .svgIcon,.u-imageSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDarker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important; color: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--buttonLight .icon:before,.u-imageSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark .icon:before,.u-imageSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal .icon:before,.u-imageSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonDark.button--filled,.u-imageSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal.button--filled,.u-imageSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--link {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-h1,.u-imageSpectrum  .ui-h2,.u-imageSpectrum  .ui-h3,.u-imageSpectrum  .ui-h4,.u-imageSpectrum  .ui-brand1,.u-imageSpectrum  .ui-brand2,.u-imageSpectrum  .ui-captionStrong {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-body,.u-imageSpectrum  .ui-caps {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-summary,.u-imageSpectrum  .ui-caption {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconLight .svgIcon,.u-imageSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--iconNormal .svgIcon,.u-imageSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconDark .svgIcon,.u-imageSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark .icon:before,.u-imageSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonDark.button--filled,.u-imageSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-imageSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-imageSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .postArticle.is-withAccentColors .markup--user,.u-imageSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--highlightFaint {background-color: rgba(255, 255, 255, 0.2) !important;}
.u-imageSpectrum .u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(255, 255, 255, 0.6) !important;}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: rgba(255, 255, 255, 0.2) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 0.2));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: rgba(255, 255, 255, 0.4) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.4), rgba(255, 255, 255, 0.4));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}.u-resetSpectrum .u-tintBgColor {background-color: rgba(255, 255, 255, 1) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(255, 255, 255, 1) 0%, rgba(255, 255, 255, 0) 100%) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 100%) !important;}
.u-resetSpectrum .u-baseColor--borderLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderDark {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--iconLight .svgIcon,.u-resetSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconNormal .svgIcon,.u-resetSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconDark .svgIcon,.u-resetSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textNormal {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDarker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--backgroundLight {background-color: rgba(0, 0, 0, 0.09803921568627451) !important;}
.u-resetSpectrum .u-baseColor--backgroundNormal {background-color: rgba(0, 0, 0, 0.2) !important;}
.u-resetSpectrum .u-baseColor--backgroundDark {background-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight .icon:before,.u-resetSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark {border-color: rgba(0, 0, 0, 0.6) !important; color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--buttonDark .icon:before,.u-resetSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important; color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal .icon:before,.u-resetSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(0, 0, 0, 0.4980392156862745) !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark.button--filled,.u-resetSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2980392156862745) !important; border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal.button--filled,.u-resetSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2) !important; border-color: rgba(0, 0, 0, 0.2) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--link {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--darken:active {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--link.link--darker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-h1,.u-resetSpectrum  .ui-h2,.u-resetSpectrum  .ui-h3,.u-resetSpectrum  .ui-h4,.u-resetSpectrum  .ui-brand1,.u-resetSpectrum  .ui-brand2,.u-resetSpectrum  .ui-captionStrong {color: rgba(0, 0, 0, 0.8) !important; fill: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum  .ui-body,.u-resetSpectrum  .ui-caps {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-summary,.u-resetSpectrum  .ui-caption {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-accentColor--borderLight {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderNormal {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderDark {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconLight .svgIcon,.u-resetSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--iconNormal .svgIcon,.u-resetSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconDark .svgIcon,.u-resetSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textDark {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundLight {background-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundNormal {background-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundDark {background-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark {border-color: rgba(0, 171, 107, 1) !important; color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark .icon:before,.u-resetSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(28, 153, 99, 1) !important; fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(2, 184, 117, 1) !important; color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(0, 171, 107, 1) !important; fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark.button--filled,.u-resetSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-resetSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(28, 153, 99, 1) !important; border-color: rgba(28, 153, 99, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-resetSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(0, 171, 107, 1) !important; border-color: rgba(0, 171, 107, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .postArticle.is-withAccentColors .markup--user,.u-resetSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(0, 171, 107, 1) !important;}</style><div class="highlightMenu" data-action-scope="_actionscope_3" style="left: 632px; top: 16413px;"><div class="highlightMenu-inner"><div class="buttonSet"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu u-accentColor--highlightStrong js-highlightMenuQuoteButton" data-action="sign-up-prompt" data-sign-in-action="quote" data-requires-token="true" data-skip-onboarding="true" data-redirect-type="quote" data-action-source="quote_menu--------------------------highlight_text"><span class="svgIcon svgIcon--highlighter svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M13.7 15.964l5.204-9.387-4.726-2.62-5.204 9.387 4.726 2.62zm-.493.885l-1.313 2.37-1.252.54-.702 1.263-3.796-.865 1.228-2.213-.202-1.35 1.314-2.37 4.722 2.616z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="quote-respond" data-redirect="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9" data-skip-onboarding="true" data-action-source="quote_menu--------------------------respond_text"><span class="svgIcon svgIcon--responseFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19.074 21.117c-1.244 0-2.432-.37-3.532-1.096a7.792 7.792 0 0 1-.703-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.662 0 8.457 3.5 8.457 7.803 0 2.058-.85 3.984-2.403 5.448.023.17.06.35.118.55.192.69.537 1.38 1.026 2.04.15.21.172.48.058.7a.686.686 0 0 1-.613.38h-.03z" fill-rule="evenodd"></path></svg></span></button><a class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--chromeless button--highlightMenu js-highlightMenuTwitterShare" href="https://medium.com/p/79a07dd44cf9/share/twitter?type=highlight&amp;text=other%20articles" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action="twitter"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></span></a><div class="buttonSet-separator"></div><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="highlight" data-redirect="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9" data-skip-onboarding="true" data-action-source="quote_menu--------------------------privatenote_text"><span class="svgIcon svgIcon--privatenoteFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M17.662 4.552H7.346A4.36 4.36 0 0 0 3 8.898v5.685c0 2.168 1.614 3.962 3.697 4.28v2.77c0 .303.35.476.59.29l3.904-2.994h6.48c2.39 0 4.35-1.96 4.35-4.35V8.9c0-2.39-1.95-4.346-4.34-4.346zM16 14.31a.99.99 0 0 1-1.003.99h-4.994C9.45 15.3 9 14.85 9 14.31v-3.02a.99.99 0 0 1 1-.99v-.782a2.5 2.5 0 0 1 2.5-2.51c1.38 0 2.5 1.13 2.5 2.51v.782c.552.002 1 .452 1 .99v3.02z"></path><path d="M14 9.81c0-.832-.674-1.68-1.5-1.68-.833 0-1.5.84-1.5 1.68v.49h3v-.49z"></path></g></svg></span></button></div></div><div class="highlightMenu-arrowClip"><span class="highlightMenu-arrow"></span></div></div></div></div></div><div class="loadingBar"></div><script>// <![CDATA[
window["obvInit"] = function (opt_embedded) {window["obvInit"]["embedded"] = opt_embedded; window["obvInit"]["ready"] = true;}
// ]]></script><script>// <![CDATA[
var GLOBALS = {"audioUrl":"https://d1fcbxp97j4nb2.cloudfront.net","baseUrl":"https://towardsdatascience.com","buildLabel":"37284-b92bb4c","currentUser":{"userId":"lo_sAdmRsl8s2Kf","isVerified":false,"subscriberEmail":"","hasPastMemberships":false,"isEnrolledInHightower":false,"isEligibleForHightower":false,"hightowerLastLockedAt":0,"isWriterProgramEnrolled":true,"isWriterProgramInvited":false,"isWriterProgramOptedOut":false,"writerProgramVersion":0,"writerProgramEnrolledAt":0,"friendLinkOnboarding":0,"hasAdditionalUnlocks":false,"hasApiAccess":false,"isQuarantined":false,"writerProgramDistributionSettingOptedIn":false},"currentUserHasUnverifiedEmail":false,"isAuthenticated":false,"isCurrentUserVerified":false,"language":"zh-tw","miroUrl":"https://cdn-images-1.medium.com","moduleUrls":{"base":"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.taBuz0BaPXEzQ0XY-OlDyQ.js","common-async":"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.A_mLXkb4Ge7UOhdBL7AHpQ.js","hightower":"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.cu_DvZdJVTyB3GCuIZGzjA.js","home-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle.E8mGTqZIRt8PdKIj5rb_6Q.js","misc-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle._iq07U-iugyd4o0z11Ll3A.js","notes":"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.K3uboaPn6_SsEx2F5Tb_LA.js","payments":"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.bPiaCD-_HYPk52L1yyY-oQ.js","posters":"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.I93Nud4U0O5nGLwcgAp67Q.js","power-readers":"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.LOR4KdNUoWnoxzgunR034A.js","pubs":"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle.gtUNNQd8niE3bfa7whdBwQ.js","stats":"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.IP6BuJ1_wMVlpXqXyiyBuA.js"},"previewConfig":{"weightThreshold":1,"weightImageParagraph":0.51,"weightIframeParagraph":0.8,"weightTextParagraph":0.08,"weightEmptyParagraph":0,"weightP":0.003,"weightH":0.005,"weightBq":0.003,"minPTextLength":60,"truncateBoundaryChars":20,"detectTitle":true,"detectTitleLevThreshold":0.15},"productName":"Medium","supportsEdit":true,"termsUrl":"//medium.com/policy/9db0094a1e0f","textshotHost":"textshot.medium.com","transactionId":"1555828781912:57d36599a125","useragent":{"browser":"chrome","family":"chrome","os":"mac","version":72,"supportsDesktopEdit":true,"supportsInteract":true,"supportsView":true,"isMobile":false,"isTablet":false,"isNative":false,"supportsFileAPI":true,"isTier1":true,"clientVersion":"","unknownParagraphsBad":false,"clientChannel":"","supportsRealScrollEvents":true,"supportsVhUnits":true,"ruinsViewportSections":false,"supportsHtml5Video":true,"supportsMagicUnderlines":true,"isWebView":false,"isFacebookWebView":false,"supportsProgressiveMedia":true,"supportsPromotedPosts":true,"isBot":false,"isNativeIphone":false,"supportsCssVariables":true,"supportsVideoSections":true,"emojiSupportLevel":1,"isSearchBot":false,"isSyndicationBot":false,"isNativeAndroid":false,"isNativeIos":false,"supportsScrollableMetabar":true},"variants":{"allow_access":true,"allow_signup":true,"allow_test_auth":"disallow","signin_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","signup_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","google_sign_in_android":true,"reengagement_notification_duration":3,"browsable_stream_config_bucket":"curated-topics","enable_dedicated_series_tab_api_ios":true,"enable_post_import":true,"available_monthly_plan":"60e220181034","available_annual_plan":"2c754bcc2995","disable_ios_resume_reading_toast":true,"is_not_medium_subscriber":true,"glyph_font_set":"m2","enable_branding":true,"enable_branding_fonts":true,"max_premium_content_per_user_under_metering":3,"enable_automated_mission_control_triggers":true,"enable_lite_profile":true,"enable_marketing_emails":true,"enable_topic_lifecycle_email":true,"enable_parsely":true,"enable_branch_io":true,"enable_ios_post_stats":true,"enable_lite_topics":true,"enable_lite_stories":true,"redis_read_write_splitting":true,"enable_tipalti_onboarding":true,"enable_annual_renewal_reminder_email":true,"enable_janky_spam_rules":"users,posts","enable_new_collaborative_filtering_data":true,"android_rating_prompt_stories_read_threshold":2,"stripe_v3":true,"enable_google_one_tap":true,"enable_email_sign_in_captcha":true,"enable_rito_post_handler":true,"enable_rito_sequence_post_recirc_query":true,"enable_primary_topic_for_mobile":true,"enable_rito_sequence_post_handler":true,"enable_logged_out_homepage_signup":true,"use_new_admin_topic_backend":true,"enable_quarantine_rules":true,"enable_lite_privacy_banner":true,"enable_simplified_welcome_email":true,"enable_digest_inbox_education_promo":true,"enable_april_meter_email_test":true},"xsrfToken":"","iosAppId":"828256236","supportEmail":"yourfriends@medium.com","fp":{"/icons/monogram-mask.svg":"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg","/icons/favicon-dev-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico","/icons/favicon-hatch-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico","/icons/favicon-medium-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico"},"authBaseUrl":"https://medium.com","imageUploadSizeMb":25,"isAuthDomainRequest":false,"domainCollectionSlug":"towards-data-science","algoliaApiEndpoint":"https://MQ57UUUQZ2-dsn.algolia.net","algoliaAppId":"MQ57UUUQZ2","algoliaSearchOnlyApiKey":"394474ced050e3911ae2249ecc774921","iosAppStoreUrl":"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8","iosAppLinkBaseUrl":"medium:","algoliaIndexPrefix":"medium_","androidPlayStoreUrl":"https://play.google.com/store/apps/details?id=com.medium.reader","googleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","androidPackage":"com.medium.reader","androidPlayStoreMarketScheme":"market://details?id=com.medium.reader","googleAuthUri":"https://accounts.google.com/o/oauth2/auth","androidScheme":"medium","layoutData":{"useDynamicScripts":false,"googleAnalyticsTrackingCode":"UA-24232453-2","jsShivUrl":"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js","useDynamicCss":false,"faviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico","faviconImageId":"1*8I-HPL0bfoIzGied-dzOvA.png","fontSets":[{"id":8,"url":"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css"},{"id":11,"url":"https://glyph.medium.com/css/m2.css"},{"id":9,"url":"https://glyph.medium.com/css/mkt.css"}],"editorFaviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico","glyphUrl":"https://glyph.medium.com"},"authBaseUrlRev":"moc.muidem//:sptth","isDnt":false,"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","archiveUploadSizeMb":100,"paymentData":{"currencies":{"1":{"label":"US Dollar","external":"usd"}},"countries":{"1":{"label":"United States of America","external":"US"}},"accountTypes":{"1":{"label":"Individual","external":"individual"},"2":{"label":"Company","external":"company"}}},"previewConfig2":{"weightThreshold":1,"weightImageParagraph":0.05,"raiseImage":true,"enforceHeaderHierarchy":true,"isImageInsetRight":true},"isAmp":false,"iosScheme":"medium","isSwBoot":false,"lightstep":{"accessToken":"ce5be895bef60919541332990ac9fef2","carrier":"{\"ot-tracer-spanid\":\"26e2b5e127e46547\",\"ot-tracer-traceid\":\"6f1ddd507a2bab11\",\"ot-tracer-sampled\":\"true\"}","host":"collector-medium.lightstep.com"},"facebook":{"key":"542599432471018","namespace":"medium-com","scope":{"default":["public_profile","email"],"connect":["public_profile","email"],"login":["public_profile","email"],"share":["public_profile","email"]}},"editorsPicksTopicId":"3985d2a191c5","popularOnMediumTopicId":"9d34e48ecf94","memberContentTopicId":"13d7efd82fb2","audioContentTopicId":"3792abbd134","brandedSequenceId":"7d337ddf1941","isDoNotAuth":false,"goldfinchUrl":"https://goldfinch.medium.com","buggle":{"url":"https://buggle.medium.com","videoUrl":"https://cdn-videos-1.medium.com","audioUrl":"https://cdn-audio-1.medium.com"},"referrerType":5,"isMeteredOut":false,"meterConfig":{"maxUnlockCount":3,"windowLength":"MONTHLY"},"partnerProgramEmail":"partnerprogram@medium.com","userResearchPrompts":[{"promptId":"lo_post_page_4","type":0,"url":"www.calendly.com"},{"promptId":"lo_home_page","type":1,"url":"www.calendly.com"},{"promptId":"lo_profile_page","type":2,"url":"www.calendly.com"}],"recaptchaKey":"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ","signinWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"countryCode":"US","bypassMeter":false,"branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","paypal":{"clientMode":"production","oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com/redeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"}},"collectionConfig":{"mediumOwnedAndOperatedCollectionIds":["544c7006046e // Human Parts","bcc38c8f6edf // Matter","444d13b52878 // OneZero","8d6b8a439e32 // Elemental"]}}
// ]]></script><script charset="UTF-8" src="./cnn_files/main-base.bundle.taBuz0BaPXEzQ0XY-OlDyQ.js" async=""></script><script>// <![CDATA[
window["obvInit"]({"value":{"id":"79a07dd44cf9","versionId":"62d3831f5c79","creatorId":"11b65705ec0","creator":{"userId":"11b65705ec0","name":"Piotr Skalski","username":"piotr.skalski92","createdAt":1526280616646,"imageId":"1*uLFtOD_rwfKeLDbWIEly8g.jpeg","backgroundImageId":"","bio":"#ComputerScience student and Frontend developer at day #React #JavaScript, #MachineLearning enthusiast at night #Kaggle, #Python, #TensorFlow.js","twitterScreenName":"PiotrSkalski92","socialStats":{"userId":"11b65705ec0","usersFollowedCount":74,"usersFollowedByCount":2570,"type":"SocialStats"},"social":{"userId":"lo_sAdmRsl8s2Kf","targetUserId":"11b65705ec0","type":"Social"},"facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"isWriterProgramEnrolled":true,"isQuarantined":false,"type":"User"},"homeCollection":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","BIG DATA","ANALYTICS"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":205636,"activeAt":1555810349405},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"1*5EUO1kUYBthpOCPzRj_l2g.png","filter":"","backgroundSize":"","originalWidth":1010,"originalHeight":376,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["8e2374e11bfb","3bc890dac04d"]}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["449f3c5f6e99","7f2f79e10e3f","4e73e55de341"],"sectionHeader":"Featured "}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["badbb1726722","7e5819af339d"],"sectionHeader":"Our Letters"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"126dff5b63d2"}},{"type":1,"postListMetadata":{"source":2,"layout":4,"number":6,"postIds":[],"sectionHeader":"Trending"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["3bf37f75a345","3920888f831c"],"sectionHeader":"Our Readers’ Guide"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["96667b06af5","f8432d67a777"],"sectionHeader":"Contribute"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["d691af11cc2f","c2c8e712c971"]}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"AI","url":"https://towardsdatascience.com/artificial-intelligence/home","topicId":"7f029b17bf96","source":"topicId"},{"type":4,"title":"Journalism","url":"https://towardsdatascience.com/data-journalism/home","topicId":"27a6ac3980c6","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":3,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"},"homeCollectionId":"7f60cf5620c9","title":"Gentle Dive into Math Behind Convolutional Neural Networks","detectedLanguage":"en","latestVersion":"62d3831f5c79","latestPublishedVersion":"62d3831f5c79","hasUnpublishedEdits":false,"latestRev":1602,"createdAt":1551964805022,"updatedAt":1555264925196,"acceptedAt":0,"firstPublishedAt":1555104438283,"latestPublishedAt":1555264925196,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"Mysteries of Neural Networks Part V","bodyModel":{"paragraphs":[{"name":"9707","type":3,"text":"Gentle Dive into Math Behind Convolutional Neural Networks","markups":[]},{"name":"3180","type":13,"text":"Mysteries of Neural Networks Part V","markups":[]},{"name":"a05a","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*k6hOViVXOteTOwaI_nCvqg.gif","originalWidth":618,"originalHeight":434,"isFeatured":true}},{"name":"4c37","type":1,"text":"Autonomous driving, healthcare or retail are just some of the areas where Computer Vision has allowed us to achieve things that, until recently, were considered impossible. Today the dream of a self driving car or automated grocery store does not sound so futuristic anymore. In fact, we are using Computer Vision every day — when we unlock the phone with our face or automatically retouch photos before posting them on social media. Convolutional Neural Networks are possibly the most crucial building blocks behind this huge successes. This time we are going to broaden our understanding of how neural networks work with ideas specific to CNNs. Be advise, the article will include quite complex math equations, but don’t be discouraged if you are not comfortable with linear algebra and differential calculus. My goal is not to make you remember those formulas, but to provide you with the intuition of what is happening underneath.","markups":[{"type":1,"start":717,"end":810}],"hasDropCap":true},{"name":"db53","type":11,"text":"","markups":[],"layout":1,"iframe":{"mediaResourceId":"938c9b44baaf2d6b74e18b015897c2c2","iframeWidth":800,"iframeHeight":166,"thumbnailUrl":"https://i.embed.ly/1/image?url=http%3A%2F%2Fi1.sndcdn.com%2Fartworks-000518693823-p0sn99-t500x500.jpg&key=a19fcc184b9711e1b4764040d3dc5c07"}},{"name":"285b","type":1,"text":"Side notes: For the first time I decided to enrich my artwork with an audio version and I kindly invite you to listen to it. You will find a link to Soundcloud above. In this article I focus mainly on things typical to CNNs. If you are looking for more general information about deep neural networks I encourage you to read my other posts from this series. As usual, full source code with visualizations and comments can be found on my GitHub. Let’s start!","markups":[{"type":3,"start":344,"end":355,"href":"https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba","title":"","rel":"","anchorType":0},{"type":3,"start":436,"end":442,"href":"https://github.com/SkalskiP/ILearnDeepLearning.py","title":"","rel":"","anchorType":0},{"type":1,"start":0,"end":11}]},{"name":"5d03","type":13,"text":"Introduction","markups":[]},{"name":"34ec","type":1,"text":"In the past we got to know the so-called densely connected neural networks. These are networks whose neurons are divided into groups forming successive layers. Each such unit is connected to every single neuron from the neighboring layers. An example of such an architecture is shown in the figure below.","markups":[],"hasDropCap":true},{"name":"ebd2","type":4,"text":"Figure 1. Densely connected neural network architecture","markups":[{"type":1,"start":0,"end":9}],"layout":1,"metadata":{"id":"1*exGQuaF5oCWTncJYY_lPhw.png","originalWidth":1521,"originalHeight":962}},{"name":"9f85","type":1,"text":"This approach works well when we solve classification problem based on a limited set of defined features — for example, we predict a football player’s position based on the statistics he logs during games. However, the situation becomes more complicated when working with photos. Of course, we could treat the brightness of each pixel as a separate feature and pass it on as an input to our dense network. Unfortunately, in order to make it work for a typical smartphone photo, our network would have to contain tens or even hundreds of millions of neurons. On the other hand, we could scale our photo down, but we would lose valuable information in the process. Right away we see that a traditional strategy does nothing for us— we need a new clever way to use as much data as possible, but at the same time reduce the number of necessary calculations and parameters. That’s when CNNs comes into play.","markups":[]},{"name":"c689","type":13,"text":"Digital photo data structure","markups":[]},{"name":"ada8","type":1,"text":"Let’s start by taking a minute to explain how digital images are stored. Most of you probably realize that they are actually huge matrices of numbers. Each such number corresponds to the brightness of a single pixel. In the RGB model, the colour image is actually composed of three such matrices corresponding to three colour channels — red, green and blue. In black-and-white images we only need one matrix. Each of these matrices stores values from 0 to 255. This range is a compromise between the efficacy of storing information about the image (256 values fit perfectly in 1 byte) and the sensitivity of the human eye (we distinguish a limited number of shades of the same colour).","markups":[],"hasDropCap":true},{"name":"65e7","type":4,"text":"Figure 2. Data structure behind digital images","markups":[{"type":1,"start":0,"end":9}],"layout":1,"metadata":{"id":"1*HPbsBA5BJovt-vrbF1C7Jg.png","originalWidth":1521,"originalHeight":1012}},{"name":"17a8","type":13,"text":"Convolution","markups":[]},{"name":"76da","type":1,"text":"Kernel convolution is not only used in CNNs, but is also a key element of many other Computer Vision algorithms. It is a process where we take a small matrix of numbers (called kernel or filter), we pass it over our image and transform it based on the values from filter. Subsequent feature map values are calculated according to the following formula, where the input image is denoted by f and our kernel by h. The indexes of rows and columns of the result matrix are marked with m and n respectively.","markups":[{"type":1,"start":112,"end":272},{"type":2,"start":389,"end":390},{"type":2,"start":409,"end":410},{"type":2,"start":481,"end":482},{"type":2,"start":487,"end":488}],"hasDropCap":true},{"name":"6e81","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*EJBQVsY0g6XqBaGgU8hYfA.gif","originalWidth":470,"originalHeight":42}},{"name":"df5e","type":4,"text":"Figure 3. Kernel convolution example","markups":[{"type":1,"start":0,"end":9}],"layout":1,"metadata":{"id":"1*32zCSTBi3giSApz1oQV-zA.gif","originalWidth":761,"originalHeight":506}},{"name":"aa25","type":1,"text":"After placing our filter over a selected pixel, we take each value from kernel and multiply them in pairs with corresponding values from the image. Finally we sum up everything and put the result in the right place in the output feature map. Above we can see how such an operation looks like in micro scale, but what is even more interesting, is what we can achieve by performing it on a full image. Figure 4 shows the results of the convolution with several different filters.","markups":[]},{"name":"aa75","type":4,"text":"Figure 4. Finding edges with kernel convolution [Original Image]","markups":[{"type":3,"start":49,"end":63,"href":"https://www.maxpixel.net/Idstein-Historic-Center-Truss-Facade-Germany-3748512","title":"","rel":"noopener","anchorType":0},{"type":1,"start":0,"end":9}],"layout":1,"metadata":{"id":"1*TAo3aselJNVwrLLr654Myg.gif","originalWidth":1600,"originalHeight":1250}},{"name":"1065","type":13,"text":"Valid and Same Convolution","markups":[]},{"name":"041d","type":1,"text":"As we have seen in Figure 3, when we perform convolution over the 6x6 image with a 3x3 kernel, we get a 4x4 feature map. This is because there are only 16 unique positions where we can place our filter inside this picture. Since our image shrinks every time we perform convolution, we can do it only a limited number of times, before our image disappears completely. What’s more, if we look at how our kernel moves through the image we see that the impact of the pixels located on the outskirts is much smaller than those in the center of image. This way we lose some of the information contained in the picture. Below you can see how the position of the pixel changes its influence on the feature map.","markups":[{"type":1,"start":223,"end":546}],"hasDropCap":true},{"name":"eb35","type":4,"text":"Figure 5. Impact of pixel position","markups":[{"type":1,"start":0,"end":9}],"layout":1,"metadata":{"id":"1*P1vkUXqHJbAbUQWDrxg8rA.gif","originalWidth":1065,"originalHeight":708}},{"name":"4011","type":1,"text":"To solve both of these problems we can pad our image with an additional border. For example, if we use 1px padding, we increase the size of our photo to 8x8, so that output of the convolution with the 3x3 filter will be 6x6. Usually in practice we fill in additional padding with zeroes. Depending on whether we use padding or not, we are dealing with two types of convolution — Valid and Same. Naming is quite unfortunate, so for the sake of clarity: Valid — means that we use the original image, Same — we use the border around it, so that the images at the input and output are the same size. In the second case, the padding width, should meet the following equation, where p is padding and f is the filter dimension (usually odd).","markups":[{"type":1,"start":452,"end":532},{"type":2,"start":677,"end":678},{"type":2,"start":694,"end":695}]},{"name":"e7fd","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*RT4wahrezNLWl4DeqWDOjw.gif","originalWidth":99,"originalHeight":46}},{"name":"afbd","type":13,"text":"Strided Convolution","markups":[]},{"name":"cc9d","type":4,"text":"Figure 6. Example of strided convolution","markups":[{"type":1,"start":0,"end":9}],"layout":1,"metadata":{"id":"1*itcofCIVsGe7rBmciJcmVw.gif","originalWidth":1065,"originalHeight":787}},{"name":"5c5f","type":1,"text":"In previous examples, we always shifted our kernel by one pixel. However, step length can also be treated as one of convolution layer hyperparameters. In Figure 6, we can see how the convolution looks like if we use larger stride. When designing our CNN architecture, we can decide to increase the step if we want the receptive fields to overlap less or if we want smaller spatial dimensions of our feature map. The dimensions of the output matrix - taking into account padding and stride - can be calculated using the following formula.","markups":[],"hasDropCap":true},{"name":"e6b3","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*HoOLVDujrz1TKJJ6ijR6Bw.gif","originalWidth":258,"originalHeight":54}},{"name":"47de","type":13,"text":"The transition to the third dimension","markups":[]},{"name":"cb02","type":1,"text":"Convolution over volume is a very important concept, which will allow us not only to work with color images, but even more importantly to apply multiple filters within a single layer. The first important rule is that the filter and the image you want to apply it to, must have the same number of channels. Basically, we proceed very much like in the example from Figure 3, nevertheless this time we multiply the pairs of values from the three-dimensional space. If we want use multiple filters on the same image, we carry out the convolution for each of them separately, stack the results one on top of the other and combine them into a whole. The dimensions of the received tensor (as our 3D matrix can be called) meet the following equation, in which: n — image size, f — filter size, nc — number of channels in the image, p —used padding, s — used stride, nf — number of filters.","markups":[{"type":1,"start":184,"end":305},{"type":1,"start":461,"end":643},{"type":2,"start":754,"end":755},{"type":2,"start":770,"end":771},{"type":2,"start":787,"end":789},{"type":2,"start":825,"end":827},{"type":2,"start":841,"end":843},{"type":2,"start":859,"end":862}],"hasDropCap":true},{"name":"4f05","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*oto8zpybb-uWB_7Uu7Nk8w.gif","originalWidth":647,"originalHeight":54}},{"name":"5783","type":4,"text":"Figure 7. Convolution over volume","markups":[{"type":1,"start":0,"end":9}],"layout":1,"metadata":{"id":"1*Ukb2msCjU3G5eS4a45f-lg.png","originalWidth":1522,"originalHeight":964}},{"name":"6ef9","type":13,"text":"Convolution Layers","markups":[]},{"name":"ea7c","type":1,"text":"The time has finally come to use everything we have learned today and to build a single layer of our CNN. Our methodology is almost identical to the one we used for densely connected neural networks, the only difference is that instead of using a simple matrix multiplication, this time we will use the convolution. Forward propagation consists of two steps. The first one is to calculate the intermediate value Z, which is obtained as a result of the convolution of the input data from the previous layer with W tensor (containing filters), and then adding bias b. The second is the application of a non-linear activation function to our intermediate value (our activation is denoted by g). Fans of matrix equations will find appropriate mathematical formulas below. If any of the operations in question is not clear to you, I highly recommend my previous article, in which I discuss in detail what is happening inside densely connected neural networks. By the way, on illustration below you can see a small visualization, describing the dimensions of tensors used in equation.","markups":[{"type":3,"start":848,"end":864,"href":"https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba","title":"","rel":"","anchorType":0},{"type":1,"start":411,"end":413},{"type":1,"start":511,"end":512},{"type":1,"start":563,"end":564},{"type":2,"start":411,"end":412}],"hasDropCap":true},{"name":"9f44","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*fkfVP6I7QXdxlnnCsxYsfA.gif","originalWidth":337,"originalHeight":19}},{"name":"bc73","type":4,"text":"Figure 8. Tensors dimensions","markups":[{"type":1,"start":0,"end":9}],"layout":1,"metadata":{"id":"1*T4FpV497IYNinpT0mzlaLA.png","originalWidth":1522,"originalHeight":1011}},{"name":"5260","type":13,"text":"Connections Cutting and Parameters Sharing","markups":[]},{"name":"67a9","type":1,"text":"At the beginning of the article I mentioned that densely connected neural networks are poor at working with images, due to the huge number of parameters that would need to be learned. Now that we understand what convolution is all about, let’s consider how it allows us to optimize the calculations. On the Figure below, the 2D convolution has been visualized in a slightly different way — neurons marked with numbers 1–9 form the input layer that receives brightness of subsequent pixels, while units A-D denotes calculated feature map elements. Last but not least, I-IV are the subsequent values from kernel — these must be learned.","markups":[],"hasDropCap":true},{"name":"a6e6","type":4,"text":"Figure 9. Connections cutting and parameters sharing","markups":[{"type":1,"start":0,"end":9}],"layout":1,"metadata":{"id":"1*6S1ltWsTUIdULzRxqueWiA.gif","originalWidth":1260,"originalHeight":904}},{"name":"b35f","type":1,"text":"Now, let’s focus on the two very important attributes of convolution layers. First of all, you can see that not all neurons in the two consecutive layers are connected to each other. For example, unit 1 only affects the value of A. Secondly, we see that some neurons share the same weights. Both of these properties mean that we have much less parameters to learn. By the way, it is worth noting that a single value from the filter affects every element of the feature map — it will be crucial in the context of backpropagation.","markups":[{"type":1,"start":77,"end":183},{"type":1,"start":232,"end":291}]},{"name":"87a8","type":13,"text":"Convolutional Layer Backpropagation","markups":[]},{"name":"96b1","type":1,"text":"Anyone who has ever tried to code their own neural network from scratch knows, that forward propagation is less than half the success. The real fun starts when you want to go back. Nowadays, we don’t need to bother with backpropagation — deep learning frameworks do it for us, but I feel it’s worth knowing what’s going on under the hood. Just like in densely connected neural networks, our goal is to calculate derivatives and later use them to update the values of our parameters in a process called gradient descent.","markups":[{"type":1,"start":339,"end":519}],"hasDropCap":true},{"name":"360d","type":1,"text":"In our calculations we will use a chain rule — which I mentioned in previous articles. We want to assess the influence of the change in the parameters on the resulting features map, and subsequently on the final result. Before we start to go into the details, let us agree on the mathematical notation that we will use — in order to make my life easier, I will abandon the full notation of the partial derivative in favour of the shortened one visible below. But remember, that when I use this notation, I will always mean the partial derivative of the cost function.","markups":[{"type":1,"start":86,"end":219}]},{"name":"18e8","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*3k9R6aUwekXXEHVrGbMitw.gif","originalWidth":496,"originalHeight":42}},{"name":"ae45","type":4,"text":"Figure 10. Input and output data for a single convolution layer in forward and backward propagation","markups":[{"type":1,"start":0,"end":10}],"layout":1,"metadata":{"id":"1*1ma11FU4okzC-csMEAU0kQ.png","originalWidth":1351,"originalHeight":720}},{"name":"2a51","type":1,"text":"Our task is to calculate dW[l] and db[l] - which are derivatives associated with parameters of current layer, as well as the value of dA[ l -1] - which will be passed to the previous layer. As shown in Figure 10, we receive the dA[l] as the input. Of course, the dimensions of tensors dW and W, db and b as well as dA and A respectively are the same. The first step is to obtain the intermediate value dZ[l] by applying a derivative of our activation function to our input tensor. According to the chain rule, the result of this operation will be used later.","markups":[{"type":1,"start":25,"end":30},{"type":1,"start":35,"end":42},{"type":1,"start":134,"end":144},{"type":1,"start":145,"end":146},{"type":1,"start":228,"end":234},{"type":1,"start":285,"end":287},{"type":1,"start":292,"end":293},{"type":1,"start":295,"end":297},{"type":1,"start":302,"end":303},{"type":1,"start":315,"end":317},{"type":1,"start":322,"end":323},{"type":1,"start":402,"end":407}]},{"name":"740f","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*UBilkUfJ6OCUpWAJlPsavg.gif","originalWidth":185,"originalHeight":22}},{"name":"a2ed","type":1,"text":"Now, we need to deal with backward propagation of the convolution itself, and in order to achieve this goal we will utilise a matrix operation called full convolution — which is visualised below. Note that during this process we use the kernel, which we previously rotated by 180 degrees. This operation can be described by the following formula, where the filter is denoted by W, and dZ[m,n] is a scalar that belongs to a partial derivative obtained from the previous layer.","markups":[{"type":1,"start":378,"end":379},{"type":1,"start":385,"end":392}]},{"name":"38c0","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*soIA9mwFw1UMaU2M8eAGEA.gif","originalWidth":243,"originalHeight":53}},{"name":"d4d8","type":4,"text":"Figure 11. Full convolution","markups":[{"type":1,"start":0,"end":10}],"layout":1,"metadata":{"id":"1*SYJpq-rOn6idEYbljdwT7w.gif","originalWidth":1065,"originalHeight":708}},{"name":"8497","type":13,"text":"Pooling Layers","markups":[]},{"name":"8427","type":1,"text":"Besides convolution layers, CNNs very often use so-called pooling layers. They are used primarily to reduce the size of the tensor and speed up calculations. This layers are simple - we need to divide our image into different regions, and then perform some operation for each of those parts. For example, for the Max Pool Layer, we select a maximum value from each region and put it in the corresponding place in the output. As in the case of the convolution layer, we have two hyperparameters available — filter size and stride. Last but not least, if you are performing pooling for a multi-channel image, the pooling for each channel should be done separately.","markups":[],"hasDropCap":true},{"name":"94df","type":4,"text":"Figure 12. Max pooling example","markups":[{"type":1,"start":0,"end":10}],"layout":1,"metadata":{"id":"1*qImgD2KGZw7ETjw3mOxNyg.gif","originalWidth":1065,"originalHeight":708}},{"name":"ddab","type":13,"text":"Pooling Layers Backpropagation","markups":[]},{"name":"461f","type":1,"text":"In this article we will discuss only max pooling backpropagation, but the rules that we will learn — with minor adjustments — are applicable to all types of pooling layers. Since in layers of this type, we don’t have any parameters that we would have to update, our task is only to distribute gradiwents appropriately. As we remember, in the forward propagation for max pooling, we select the maximum value from each region and transfer them to the next layer. It is therefore clear that during back propagation, the gradient should not affect elements of the matrix that were not included in the forward pass. In practice, this is achieved by creating a mask that remembers the position of the values used in the first phase, which we can later utilize to transfer the gradients.","markups":[],"hasDropCap":true},{"name":"4258","type":4,"text":"Figure 13. Max pooling backward pass","markups":[{"type":1,"start":0,"end":10}],"layout":1,"metadata":{"id":"1*jhW0G_vJsYCQpphu50yj2Q.gif","originalWidth":1065,"originalHeight":913}},{"name":"972f","type":13,"text":"Conclusion","markups":[]},{"name":"3554","type":1,"text":"Congratulations if you managed to get here. Big thanks for the time spent reading this article. If you liked the post, consider sharing it with your friend, or two friends or five friends. If you have noticed any mistakes in the way of thinking, formulas, animations or code, please let me know.","markups":[],"hasDropCap":true},{"name":"8e38","type":1,"text":"This article is another part of the “Mysteries of Neural Networks” series, if you haven’t had the opportunity yet, read the other articles. Also, if you like my job so far, follow me on Twitter and Medium and see other projects I’m working on, on GitHub and Kaggle. Stay curious!","markups":[{"type":3,"start":124,"end":138,"href":"https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a","title":"","rel":"nofollow noopener","anchorType":0},{"type":3,"start":186,"end":193,"href":"https://twitter.com/PiotrSkalski92","title":"","rel":"noopener nofollow noopener","anchorType":0},{"type":3,"start":198,"end":204,"href":"https://medium.com/@piotr.skalski92","title":"","rel":"","anchorType":0},{"type":3,"start":247,"end":253,"href":"https://github.com/SkalskiP","title":"","rel":"noopener nofollow noopener","anchorType":0},{"type":3,"start":258,"end":264,"href":"https://www.kaggle.com/skalskip","title":"","rel":"noopener nofollow noopener","anchorType":0}]},{"name":"cd82","type":4,"text":"","markups":[],"layout":6,"metadata":{"id":"1*0ftx4YXKIvvHjGPovjkanw.png","originalWidth":350,"originalHeight":100},"href":"https://github.com/SkalskiP/ILearnDeepLearning.py"},{"name":"b1d0","type":4,"text":"","markups":[],"layout":7,"metadata":{"id":"1*GFJaJiJ7TN5GxroF6G-xjQ.png","originalWidth":350,"originalHeight":100},"href":"https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795?source=---------5------------------"},{"name":"860b","type":4,"text":"","markups":[],"layout":7,"metadata":{"id":"1*-ObBrMMfnVFCG5u--QOZ6g.png","originalWidth":350,"originalHeight":100},"href":"https://twitter.com/PiotrSkalski92"}],"sections":[{"name":"5bcc","startIndex":0},{"name":"4660","startIndex":59}]},"postDisplay":{"coverless":true}},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"1*k6hOViVXOteTOwaI_nCvqg.gif","filter":"","backgroundSize":"","originalWidth":618,"originalHeight":434,"strategy":"resample","height":0,"width":0},"wordCount":2430,"imageCount":25,"readingTime":11.169811320754716,"subtitle":"Mysteries of Neural Networks Part V","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":533,"socialRecommends":[],"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":67625,"metadata":{"postCount":67625,"coverImage":{"id":"1*k6hOViVXOteTOwaI_nCvqg.gif","originalWidth":618,"originalHeight":434,"isFeatured":true}},"type":"Tag"},{"slug":"deep-learning","name":"Deep Learning","postCount":16738,"metadata":{"postCount":16738,"coverImage":{"id":"1*k6hOViVXOteTOwaI_nCvqg.gif","originalWidth":618,"originalHeight":434,"isFeatured":true}},"type":"Tag"},{"slug":"neural-networks","name":"Neural Networks","postCount":5103,"metadata":{"postCount":5103,"coverImage":{"id":"1*k6hOViVXOteTOwaI_nCvqg.gif","originalWidth":618,"originalHeight":434,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2042,"metadata":{"postCount":2042,"coverImage":{"id":"1*k6hOViVXOteTOwaI_nCvqg.gif","originalWidth":618,"originalHeight":434,"isFeatured":true}},"type":"Tag"},{"slug":"data-science","name":"Data Science","postCount":44484,"metadata":{"postCount":44484,"coverImage":{"id":"1*k6hOViVXOteTOwaI_nCvqg.gif","originalWidth":618,"originalHeight":434,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":2,"links":{"entries":[{"url":"https://www.maxpixel.net/Idstein-Historic-Center-Truss-Facade-Germany-3748512","alts":[],"httpStatus":200},{"url":"https://twitter.com/PiotrSkalski92","alts":[{"type":2,"url":"twitter://user?screen_name=PiotrSkalski92"},{"type":3,"url":"twitter://user?screen_name=PiotrSkalski92"}],"httpStatus":200},{"url":"https://github.com/SkalskiP/ILearnDeepLearning.py","alts":[],"httpStatus":200},{"url":"https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a","alts":[{"type":2,"url":"medium://p/953458db800a"},{"type":3,"url":"medium://p/953458db800a"}],"httpStatus":200},{"url":"https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba","alts":[{"type":2,"url":"medium://p/17660bc376ba"},{"type":3,"url":"medium://p/17660bc376ba"}],"httpStatus":200},{"url":"https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795?source=---------5------------------","alts":[{"type":2,"url":"medium://p/ae7e74410795"},{"type":3,"url":"medium://p/ae7e74410795"}],"httpStatus":200},{"url":"https://github.com/SkalskiP","alts":[],"httpStatus":200},{"url":"https://medium.com/@piotr.skalski92","alts":[{"type":2,"url":"medium://@piotr.skalski92"},{"type":3,"url":"medium://@piotr.skalski92"}],"httpStatus":200},{"url":"https://www.kaggle.com/skalskip","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1555264928667},"isLockedPreviewOnly":false,"takeoverId":"","metaDescription":"","totalClapCount":2100,"sectionCount":2,"readingList":0,"topics":[{"topicId":"1eca0103fff3","slug":"machine-learning","createdAt":1534449726145,"deletedAt":0,"image":{"id":"1*gFJS3amhZEg_z39D5EErVg@2x.png","originalWidth":2800,"originalHeight":1750},"name":"Machine Learning","description":"Teaching the learners.","relatedTopics":[],"visibility":1,"relatedTags":[],"type":"Topic"},{"topicId":"ae5d4995e225","slug":"data-science","createdAt":1493923906289,"deletedAt":0,"image":{"id":"1*NHWOEki_ncCX-xzbKtkEWw@2x.jpeg","originalWidth":5760,"originalHeight":3840},"name":"Data Science","description":"Query this.","relatedTopics":[],"visibility":1,"relatedTags":[],"type":"Topic"}]},"coverless":true,"slug":"gentle-dive-into-math-behind-convolutional-neural-networks","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"1*k6hOViVXOteTOwaI_nCvqg.gif","originalWidth":618,"originalHeight":434,"isFeatured":true}},{"name":"9707","type":3,"text":"Gentle Dive into Math Behind Convolutional Neural Networks","markups":[],"alignment":1},{"name":"3180","type":13,"text":"Mysteries of Neural Networks Part V","markups":[],"alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"Mysteries of Neural Networks Part V"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9","approvedHomeCollectionId":"7f60cf5620c9","approvedHomeCollection":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","BIG DATA","ANALYTICS"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":205636,"activeAt":1555810349405},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"1*5EUO1kUYBthpOCPzRj_l2g.png","filter":"","backgroundSize":"","originalWidth":1010,"originalHeight":376,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["8e2374e11bfb","3bc890dac04d"]}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["449f3c5f6e99","7f2f79e10e3f","4e73e55de341"],"sectionHeader":"Featured "}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["badbb1726722","7e5819af339d"],"sectionHeader":"Our Letters"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"126dff5b63d2"}},{"type":1,"postListMetadata":{"source":2,"layout":4,"number":6,"postIds":[],"sectionHeader":"Trending"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["3bf37f75a345","3920888f831c"],"sectionHeader":"Our Readers’ Guide"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["96667b06af5","f8432d67a777"],"sectionHeader":"Contribute"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["d691af11cc2f","c2c8e712c971"]}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"AI","url":"https://towardsdatascience.com/artificial-intelligence/home","topicId":"7f029b17bf96","source":"topicId"},{"type":4,"title":"Journalism","url":"https://towardsdatascience.com/data-journalism/home","topicId":"27a6ac3980c6","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":3,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"},"newsletterId":"","webCanonicalUrl":"https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9","mediumUrl":"https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":3,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"primaryTopic":{"topicId":"1eca0103fff3","slug":"machine-learning","createdAt":1534449726145,"deletedAt":0,"image":{"id":"1*gFJS3amhZEg_z39D5EErVg@2x.png","originalWidth":2800,"originalHeight":1750},"name":"Machine Learning","description":"Teaching the learners.","relatedTopics":[],"visibility":1,"relatedTags":[],"type":"Topic"},"primaryTopicId":"1eca0103fff3","type":"Post"},"mentionedUsers":[],"collaborators":[],"hideMeter":false,"collectionUserRelations":[],"mode":null,"references":{"User":{"11b65705ec0":{"userId":"11b65705ec0","name":"Piotr Skalski","username":"piotr.skalski92","createdAt":1526280616646,"imageId":"1*uLFtOD_rwfKeLDbWIEly8g.jpeg","backgroundImageId":"","bio":"#ComputerScience student and Frontend developer at day #React #JavaScript, #MachineLearning enthusiast at night #Kaggle, #Python, #TensorFlow.js","twitterScreenName":"PiotrSkalski92","socialStats":{"userId":"11b65705ec0","usersFollowedCount":74,"usersFollowedByCount":2570,"type":"SocialStats"},"social":{"userId":"lo_sAdmRsl8s2Kf","targetUserId":"11b65705ec0","type":"Social"},"facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"isWriterProgramEnrolled":true,"isQuarantined":false,"type":"User"}},"Collection":{"7f60cf5620c9":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","BIG DATA","ANALYTICS"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":205636,"activeAt":1555810349405},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"1*5EUO1kUYBthpOCPzRj_l2g.png","filter":"","backgroundSize":"","originalWidth":1010,"originalHeight":376,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["8e2374e11bfb","3bc890dac04d"]}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["449f3c5f6e99","7f2f79e10e3f","4e73e55de341"],"sectionHeader":"Featured "}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["badbb1726722","7e5819af339d"],"sectionHeader":"Our Letters"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"126dff5b63d2"}},{"type":1,"postListMetadata":{"source":2,"layout":4,"number":6,"postIds":[],"sectionHeader":"Trending"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["3bf37f75a345","3920888f831c"],"sectionHeader":"Our Readers’ Guide"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["96667b06af5","f8432d67a777"],"sectionHeader":"Contribute"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["d691af11cc2f","c2c8e712c971"]}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"AI","url":"https://towardsdatascience.com/artificial-intelligence/home","topicId":"7f029b17bf96","source":"topicId"},{"type":4,"title":"Journalism","url":"https://towardsdatascience.com/data-journalism/home","topicId":"27a6ac3980c6","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":3,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"}},"Social":{"11b65705ec0":{"userId":"lo_sAdmRsl8s2Kf","targetUserId":"11b65705ec0","type":"Social"}},"SocialStats":{"11b65705ec0":{"userId":"11b65705ec0","usersFollowedCount":74,"usersFollowedByCount":2570,"type":"SocialStats"}}}})
// ]]></script><div class="surface-scrollOverlay"></div><script charset="UTF-8" src="./cnn_files/main-common-async.bundle.A_mLXkb4Ge7UOhdBL7AHpQ.js"></script><script charset="UTF-8" src="./cnn_files/main-notes.bundle.K3uboaPn6_SsEx2F5Tb_LA.js"></script><script id="parsely-cfg" src="./cnn_files/p.js"></script><script type="text/javascript">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0); branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled':  false }, function(err, data) {});</script></body></html>